{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fc60084b884af807b1eaffbd4e24c7d",
     "grade": false,
     "grade_id": "cell-f7171899571b05ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Graded Lab 5\n",
    "\n",
    "Hello ! Welcome to Graded Lab of Module 5.\n",
    "\n",
    "In the last assignment we had worked on missing values & outliers.\n",
    "Its high time when we look at the feature engineering & Principal component analysis.\n",
    "\n",
    "**So lets go ahead with the last graded assignment for the course !**\n",
    "\n",
    "In case if you are not able to recollect the problem description and data description then mentioning it below.\n",
    "\n",
    "Lets look at the problem statement,\n",
    "\n",
    "*Client: ABC Retail, Incorporated, rest-of-the-world division* \n",
    "\n",
    "***Project name: Online retail sales analysis*** \n",
    "\n",
    "An online retailer, ABC, Inc., operates in nearly 100 countries worldwide, selling furniture, office supplies and technology products to customers in three segments: consumer, corporate and home office. ABC, Inc. is a US-based company, and it has two major divisions: US and rest of the world. We are working with the rest of the world division of the company. \n",
    "\n",
    "They have provided us with online sales transaction data from 2011 to 2014.\n",
    "\n",
    "We are given 3 datasets:-\n",
    "\n",
    "1. Data on each sale; 51290 records; all data in US dollars\n",
    "It contains fields like\n",
    "**order_id** (identifier) ,order_date ,ship_date ,ship_mode ,**customer_id**(identifier) ,product_id ,category ,sub_category ,product_name ,sales ,quantity ,discount ,profit ,shipping_cost ,order_priority ,**vendor_code** (identifier) \n",
    "\n",
    "\n",
    "2. Data on the customers; 1590 records \n",
    "It contains fields like\n",
    "**customer_id** (identifier) ,customer_name ,city ,state ,country ,postal_code ,segment ,market ,region \n",
    "\n",
    "3. Data on vendors who supply the retailer; 65 records \n",
    "It contains fields like\n",
    "vendor ,**vendor_code** (identifier) \n",
    "\n",
    "We need to analyze the data and need to provide answer to different questions asked by company officials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor update: Jan 29, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bc1197652bf32abbd6c75aa91d59be8",
     "grade": false,
     "grade_id": "cell-4c17e0403c1c8961",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "### Reading sales data\n",
    "sales = pd.read_csv('sales_data.csv')\n",
    "\n",
    "### Reading customer data\n",
    "cust = pd.read_csv(r'customers.csv',encoding='iso-8859-1')\n",
    "\n",
    "### Reading vendor data\n",
    "vend = pd.read_csv(r'vendors.csv')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00eefe9f054d05c8c11ebcfe9bc04a5b",
     "grade": false,
     "grade_id": "cell-4dc354b2761c4e3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In order to solve the next questions , we need to combine all the 3 datasets into a single dataframe such that every details of sales dataframe are intact. So here we have written a data processing function.\n",
    "There are 2 tasks which are to be performed.\n",
    "1. Merge/ Join all the 3 datasets into a single dataframe such that every details of sales dataframe are intact. (Understand which should be the joining key , type of join , refer .merge() function of pandas)\n",
    "2. Convert 'order_date' into a datetime column.\n",
    "**Return output as a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb96071fa0009e8888d15cd2e59a2839",
     "grade": false,
     "grade_id": "cell-171f8d30f5d84056",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#### data_merging & order_date processing , data1 will be sales , data2 will be customer dataset & data3 will be vendor dataset.\n",
    "\n",
    "def data_process(data1,data2,data3):\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da3c5d11eca78dbf422924bf20f58955",
     "grade": false,
     "grade_id": "cell-45cced5365115e88",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales= data_process(data1=sales.copy(),data2=cust.copy(),data3=vend.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40bc744c3c305203bf9d8b365a59b4b7",
     "grade": true,
     "grade_id": "cell-61ebe95bf598597b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sales['order_date'].dtypes=='<M8[ns]' ,'Make sure if you have converted order_date into a datetime format correctly or not.'\n",
    "assert sales.shape== (51290,26) ,'Checking size and shape of dataframe after merging is a very important check.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be2d14217e8998c2e6cdc3d0ba26c154",
     "grade": false,
     "grade_id": "cell-71fb2e2dc8baad31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.1) Create a feature for identifying which orders are ordered on weekends. Flag will take value 1 if order is ordered on weekends & 0 otherwise. (Sat & Sun are weekends). Return  the output series.\n",
    "\n",
    "Hint: Think of using weekday() function, consider'order_date' as the required columns for computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be1babac654c54c4ac61e7b6923eaf2e",
     "grade": false,
     "grade_id": "cell-da758c3c17ca0ef3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def weekend_flag(data):\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "561e9234baa3650bf2b493de38bbc08b",
     "grade": false,
     "grade_id": "cell-bb6f0475fbd0bab4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['weekend_orders']=weekend_flag(data=sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7b3c1c7bd6dacba32dab07ea694e39d",
     "grade": true,
     "grade_id": "cell-12c0ef94c14c3ef0",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert all(sales['weekend_orders'].unique()==np.array([0, 1])) ,'Make sure that you have created flag correctly'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbffc5d6f18565d556e322491b041b57",
     "grade": false,
     "grade_id": "cell-92abb7f69b91b506",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.2) We wish to create a feature called 'discount_per_quantity'. Write a functional code to compute ratio of 2 columns. Return  the output series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a4553dfa1605ae8c0cc97c832678452",
     "grade": false,
     "grade_id": "cell-bf222819379099c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def feature_1(data,col1,col2):\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3952efb9c9a5e72965053d005b24e6a",
     "grade": false,
     "grade_id": "cell-fdf019e6c20aa45e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['discount_per_quantity']= feature_1(data=sales,col1='discount',col2='quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eef990a45921580d13ec0179efa3491d",
     "grade": true,
     "grade_id": "cell-1d1c9c0070ebdf4e",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert round(sales['discount_per_quantity'].mean(),4)==0.0643,'Make sure that you have created feature correctly.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dbe4251dfc38440a7048e4ac4092e7a",
     "grade": false,
     "grade_id": "cell-04ae737147acedb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.3) Create a feature for finding cumulative sales for every customer. Return  the output series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69e435bdc1ceddfdb8f8c7fd5b067e6d",
     "grade": false,
     "grade_id": "cell-23b8a0fddaa72e30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cumulative_sales(data):\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19dbda090f1c9bba93f2fef835d405d8",
     "grade": false,
     "grade_id": "cell-ce218cadc5b9b7b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Sorting the dataframe wrto customer_id & order_date\n",
    "sales.sort_values(['customer_id','order_date'],ascending=[1,1],inplace=True)\n",
    "### Applying cumulative_sales function\n",
    "sales['cumulative_sales']=cumulative_sales(data=sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e06c34e321f5e2e4f28e0be7918ece13",
     "grade": true,
     "grade_id": "cell-f88f29cf32252ab7",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert round(sales[sales['customer_id']=='ZC-21910']['cumulative_sales'].max(),2)==28472.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4128b1e3bd8a63733021c2a806f88dd0",
     "grade": false,
     "grade_id": "cell-edca82aa344fa2ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.4) Please demonstrate how to enhance a given dataset by introducing a new feature that records the frequency of same-day purchases made by each customer. The desired outcome should be a modified dataframe containing a variable named 'same_day_purchase_frequency' which accurately portrays the same-day purchase behavior of individual customers.\n",
    "\n",
    "\n",
    "Hint:\n",
    "\n",
    "1.Same_day_purchase_frequency will be the frequency of the orders made on same day. If customer 'ABC' has placed 2 orders on 2nd Jan 23 then 'same_day_purchase_frequency'for this customer for 2nd Jan 23 will be 2. This is still at Customer * Date level\n",
    "\n",
    "2.If customer  'ABC' has made say 10 such frequency transactions where frequency of same day purchase >1. Then'same_day_frequency_purchase' for customer will be 10. This is our final answer at Customer level.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdb2743d81b7f441c77e26e51ba40bac",
     "grade": false,
     "grade_id": "cell-11502c58370a30cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def same_day_purchase(data):\n",
    "    # your code here\n",
    "    \n",
    "    # Group by 'customer_id' and date, and count the orders, store count of orders in variable named 'order_count'\n",
    "    order_counts = None\n",
    "    \n",
    "    # Filter for same-day purchases (order_count > 1)\n",
    "    same_day_purchases = order_counts[order_counts['order_count'] > None]\n",
    "    \n",
    "    \n",
    "    # Group by 'customer_id' and calculate the same-day purchase frequency , name that column as 'same_day_purchase_frequency'\n",
    "    same_day_purchase_frequency = None\n",
    "    \n",
    "    # Merge the result with the original DataFrame to add the same-day purchase frequency as a new column  \n",
    "    data = None\n",
    "\n",
    "\n",
    "    # Fill missing values with 0 (for customers with no same-day purchases)\n",
    "    None\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9485edecbbb7cf8550559814732b784",
     "grade": true,
     "grade_id": "cell-1a74a24a4da6dd2d",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales_new=same_day_purchase(data=sales.copy())\n",
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert float(sales_new[sales_new['customer_id']=='ZC-11910']['same_day_purchase_frequency'].unique())==0,'Make sure that you have created variable correctly.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64022a5ba581da06b8e8c96ae268fb99",
     "grade": false,
     "grade_id": "cell-7bdd8d0b6ca47c10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.5) Create a variable which will calculate weighted sales per market. Return  the output series.\n",
    "Weights for every market are :-'LATAM':1, 'EMEA':1.3, 'Africa':2.7, 'Canada':1.4, 'EU':2.8, 'APAC':3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20c298d50c1a843850662da6f77a0f4f",
     "grade": false,
     "grade_id": "cell-47084e349b64bd0d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def weighted_sales(data):\n",
    "    # Write a lambda function & apply it to dataframe.Kindly ignore raiseNotImplementError\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f027b99d898df5ff494ef6222aa01040",
     "grade": false,
     "grade_id": "cell-e9fad939365ebe57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['weighted_market_sales']=weighted_sales(data=sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82d66c7c73edac8f37f383cbfc68fafc",
     "grade": true,
     "grade_id": "cell-389d62fab17c8c2f",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert round(float(sales[(sales['market']=='Africa') & (round(sales['sales'],4)==58.83)]['weighted_market_sales'].unique()),2)==158.84, 'Make sure that ypu have created column correctly.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9afa77f2faa0eb29cbeb7b2c0dd9381d",
     "grade": false,
     "grade_id": "cell-257ca79e2212fc23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Most of the variables in our data are categorical in nature & for further anlysis purpose if we convert them by ordinal encoding or one hot encoding, we will be left with too many variables.\n",
    "If we have too many variables in the data , it might cause trouble in later stages like machine learning model building.\n",
    "1. Having too many variables can lead to overfitting and poor generalization to new data.\n",
    "2. It can make it difficult to analyze and interpret the data and identify the most important variables.\n",
    "3. It can increase computational complexity and time required to build and train a model.\n",
    "\n",
    "How to deal with this ?\n",
    "\n",
    "Wait , we have learned about **Principal component analysis** , we can leverage that method here for **dimensionality reduction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63302da6ba845b2859f2cee3e5198f4d",
     "grade": false,
     "grade_id": "cell-532602ee41242bbd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.6 ) Complete the following code for PCA implementation. Return the no of PC's required for capturing the 80% of variation, variance explained by the PC's ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73f56d08b62547c5a91e2fa94ccef16b",
     "grade": false,
     "grade_id": "cell-033f0d1768c98329",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def PCA(data,target=0.80):\n",
    "    # your code here\n",
    "    \n",
    "    # Treating ordinal variable ,\n",
    "    # order_priority : 'Medium':2, 'Low':1, 'High':3, 'Critical':4 \n",
    "    data['order_priority_encoded']=data['order_priority'].map(None) # Write your code in place of None\n",
    "\n",
    "    \n",
    "    # Treating missing values\n",
    "    # Impute the missing values in 'order_prioirty_encoded','ship_mode' by mode, \n",
    "    data['order_priority_encoded']=None # Write your code in place of None\n",
    "    data['ship_mode']=None # Write your code in place of None\n",
    "\n",
    "    \n",
    "    # Treating Nominal variables ,'ship_mode','category','sub_category' (while encoding them make sure to select k-1 dummy variables for a variable with k categories)\n",
    "    data=None # Write your code in place of None\n",
    "\n",
    "    # Final data selection\n",
    "    # Select all the variables with 'sales','quantity','discount','profit','shipping_cost','order_priority_encoded' & dummies in 'ship_mode','category','sub_category'.\n",
    "    data_1=data[['sales','quantity','discount','profit','shipping_cost','order_priority_encoded','ship_mode_Same Day','ship_mode_Second Class','ship_mode_Standard Class','category_Office Supplies','category_Technology','sub_category_Appliances','sub_category_Art','sub_category_Binders','sub_category_Bookcases','sub_category_Chairs','sub_category_Copiers','sub_category_Envelopes','sub_category_Fasteners','sub_category_Furnishings','sub_category_Labels','sub_category_Machines','sub_category_Paper','sub_category_Phones','sub_category_Storage','sub_category_Supplies','sub_category_Tables']]\n",
    "\n",
    "    \n",
    "    # Standardize the data\n",
    "    sc = StandardScaler()\n",
    "    \n",
    "    cols = ['sales','quantity','discount','profit','shipping_cost','order_priority_encoded']\n",
    "    for col in cols:\n",
    "        data_1[col] = None # Write your code in place of None\n",
    "\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    # Create a PCA instance    \n",
    "    pca = PCA()\n",
    "    \n",
    "    # Fit PCA to the scaled data\n",
    "    pca.fit(None) # Write your code in place of None\n",
    "    \n",
    "    #  Calculate cumulative explained variance\n",
    "    explained_variance_ratio = None # Write your code in place of None\n",
    "    cumulative_variance = None # Write your code in place of None\n",
    "    \n",
    "    \n",
    "    target_variation=target\n",
    "    n_components = np.argmax(cumulative_variance >= target_variation) + 1\n",
    " \n",
    "    \n",
    "    # Excellent we got no of pcs which are required for capturing the target variation in the data\n",
    "    \n",
    "    ### Fitting PCA again with no of pc's we got above.\n",
    "    pca = PCA(n_components=n_components)\n",
    "    \n",
    "    # Fit PCA to the scaled data\n",
    "    pca.fit(None) # Write your code in place of None\n",
    "    \n",
    "    #  Calculate cumulative explained variance\n",
    "    explained_variance_ratio = None # Write your code in place of None\n",
    "       \n",
    "    return n_components,explained_variance_ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1283ef2455ee18599ddbfc61cf61a6aa",
     "grade": true,
     "grade_id": "cell-095ce6ebc95af61e",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert type(PCA(data=sales.copy())[0])==np.int64 , 'Number of components required for capturing target variation should be in integer format.'\n",
    "assert type(PCA(data=sales.copy())[1])==np.ndarray , 'Type of variation captured should be in an array format.'\n",
    "assert [round(x,4) for x in list(PCA(data=sales.copy())[1])][0]==0.3012, 'Make sure that you are returning correct values for output.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6de4b32f924ec7a62617b3570a32ecfa",
     "grade": false,
     "grade_id": "cell-99f83690c838e50a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.7) How much variation was explained by 3rd principal component ? \n",
    "**Output should be rounded upto 4 digits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b1d6d3561148f2fb0ea58db6f853f08",
     "grade": false,
     "grade_id": "cell-d668bca10bcf9149",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def var_expl(variation_explained):\n",
    "    # Kindly ignore raiseNotImplementError   \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2b2d2a933ca3017b59536de505adc48",
     "grade": true,
     "grade_id": "cell-cf2fbc4c16e8ba3d",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
