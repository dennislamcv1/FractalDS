{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013e00f4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aead60dbe4aab181e67a59dcec087c6b",
     "grade": false,
     "grade_id": "cell-863e01b9f03e4a8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Graded Lab 4\n",
    "\n",
    "Hello ! Welcome to Graded Lab of Module 4.\n",
    "\n",
    "In the last assignment we had worked on correlation , hypothesis which business wanted us to test.\n",
    "Its high time when we look at the missing values & outliers stuff.\n",
    "**Here we will work on missing values & outliers.**\n",
    "\n",
    "In case if you are not able to recollect the problem description and data description then mentioning it below.\n",
    "\n",
    "Lets look at the problem statement,\n",
    "\n",
    "*Client: ABC Retail, Incorporated, rest-of-the-world division* \n",
    "\n",
    "***Project name: Online retail sales analysis*** \n",
    "\n",
    "An online retailer, ABC, Inc., operates in nearly 100 countries worldwide, selling furniture, office supplies and technology products to customers in three segments: consumer, corporate and home office. ABC, Inc. is a US-based company, and it has two major divisions: US and rest of the world. We are working with the rest of the world division of the company. \n",
    "\n",
    "They have provided us with online sales transaction data from 2011 to 2014.\n",
    "\n",
    "We are given 3 datasets:-\n",
    "\n",
    "1. Data on each sale; 51290 records; all data in US dollars\n",
    "It contains fields like\n",
    "**order_id** (identifier) ,order_date ,ship_date ,ship_mode ,**customer_id**(identifier) ,product_id ,category ,sub_category ,product_name ,sales ,quantity ,discount ,profit ,shipping_cost ,order_priority ,**vendor_code** (identifier) \n",
    "\n",
    "\n",
    "2. Data on the customers; 1590 records \n",
    "It contains fields like\n",
    "**customer_id** (identifier) ,customer_name ,city ,state ,country ,postal_code ,segment ,market ,region \n",
    "\n",
    "3. Data on vendors who supply the retailer; 65 records \n",
    "It contains fields like\n",
    "vendor ,**vendor_code** (identifier) \n",
    "\n",
    "We need to analyze the data and need to provide answer to different questions asked by company officials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe8545",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7442207fb33a683cc6602a682d1c108",
     "grade": false,
     "grade_id": "cell-ed16b8e1f54252ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "### Reading sales data\n",
    "sales = pd.read_csv('sales_data_M4.csv')\n",
    "\n",
    "### Reading customer data\n",
    "cust = pd.read_csv(r'customers.csv',encoding='iso-8859-1')\n",
    "\n",
    "### Reading vendor data\n",
    "vend = pd.read_csv(r'vendors.csv')\n",
    "\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6796c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "#pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format','{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f8995",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273973ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e986d",
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "868201adf0e3beea45c39e2a4849188a",
     "grade": false,
     "grade_id": "cell-78efe7e0424ff809",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In order to solve the next questions , we need to combine all the 3 datasets into a single dataframe such that every details of sales dataframe are intact. So here we have written a data processing function.\n",
    "There are 2 tasks which are to be performed.\n",
    "1. Merge/ Join all the 3 datasets into a single dataframe such that every details of sales dataframe are intact. (Understand which should be the joining key , type of join , refer .merge() function of pandas)\n",
    "2. Convert 'order_date' into a datetime column.\n",
    "**Return output as a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0721e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fce96ba65cc5a5db25571a75d2347ca",
     "grade": false,
     "grade_id": "cell-760043ec960a09cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#### data_merging & order_date processing , data1 will be sales , data2 will be customer dataset & data3 will be vendor dataset.\n",
    "\n",
    "def data_process(data1,data2,data3):\n",
    "    df = data1.merge(right=data3, how=\"left\", on=\"vendor_code\")\n",
    "    df2 = df.merge(right=data2, how=\"left\", on=\"customer_id\")\n",
    "    df2[\"order_date\"] = pd.to_datetime(df2['order_date'], format='%d/%m/%Y')\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8640dbb0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33f7110cf96724cd31f65c6ce99f3e4c",
     "grade": false,
     "grade_id": "cell-e8c25b222f675992",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales= data_process(data1=sales.copy(),data2=cust.copy(),data3=vend.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a33d1b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a67642ea4eef0f94a4e3a46a6081afa1",
     "grade": true,
     "grade_id": "cell-24e204e9afc2c313",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sales['order_date'].dtypes=='<M8[ns]' ,'Make sure if you have converted order_date into a datetime format correctly or not.'\n",
    "assert sales.shape== (51290,26) ,'Checking size and shape of dataframe after merging is a very important check.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6b7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2be07c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbdd9d97abd1fb4a8fc6b22845b5307a",
     "grade": false,
     "grade_id": "cell-7e22460af514a787",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that in this dataset we are purposefully introducing some of the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13311a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccbe7183c0629c7d646bd2a701a65e80",
     "grade": false,
     "grade_id": "cell-867679f736a58367",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.1 Return column names & missing values percentage for the columns which have % misisng value >50. Output should be a dictionary. For eg:- { column_name : %}, make sure to round off percentages to 2 decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalna = sales.isnull().sum().sum()\n",
    "totalna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdf = pd.DataFrame(sales.isnull().sum(), columns=[\"no\"]).reset_index()\n",
    "missingdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdf[\"%\"] = round((missingdf[\"no\"]/totalna * 100),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edaee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ce995",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdf.loc[\"postal_code\"][\"%\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb016e",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31e918",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "228f97ed1aabf7db12d62ccf5d29527c",
     "grade": false,
     "grade_id": "cell-eaa4ef1cb3c93902",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def missing_value_col(data):\n",
    "    # your code here\n",
    "    # Calculate missing value percentages for each column\n",
    "    missing_percentage = (data.isnull().sum() / len(data)) * 100\n",
    "    \n",
    "    # Filter columns with missing values > 50%\n",
    "    missing_columns = missing_percentage[missing_percentage > 50]\n",
    "    \n",
    "    # Round off percentages to 2 decimals\n",
    "    missing_columns = missing_columns.round(2)\n",
    "\n",
    "    # Convert the result to a dictionary\n",
    "    missing_columns_dict = missing_columns.to_dict()\n",
    "    \n",
    "    return missing_columns_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b666d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15a1dadb76503951152a3859e982aaf6",
     "grade": true,
     "grade_id": "cell-6d0d4c99764805c4",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d640e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_col(data=sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b636b7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb8633889e246a9d9cda5f41cf0770e7",
     "grade": false,
     "grade_id": "cell-00e1cff3e5f47a7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### **Senior data scientists after consulting with the business have decided that such columns needs to be dropped before going further.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d222bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "daeeadeee84f44971acd919fd87992ed",
     "grade": false,
     "grade_id": "cell-26857c8737cf80a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "high_missing_col=list(missing_value_col(data=sales).keys()) #Enter the columns with high % of missing values\n",
    "### We will drop columns with such high missing values\n",
    "sales.drop(high_missing_col,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d39b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8682dd5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c96de899447751e3edc9661326e762bb",
     "grade": false,
     "grade_id": "cell-e795cfc2b6847586",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.2 Fill the missing data in 'category' column with appropriate method.  \n",
    "(Hint:- Remember variable 'category' & 'sub-category' are related & hierachy goes like this category -> sub-category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc48ff64",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7161528af2accdb5397c22ff972ec375",
     "grade": false,
     "grade_id": "cell-e10cc0483013a3f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Approach:-\n",
    "\n",
    "1. Create a key-pair dictionary where key will be product category & pair values will be sub-categories.\n",
    "\n",
    "2. Wherever category value is missing check for corresponding sub-category value. \n",
    "\n",
    "3. From sub-category value trace back its original product category value by looking in dictionary, get a product value.\n",
    "\n",
    "4. Fill the blank product category value by the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce57fda3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f31241551220ce43e62bbf27b52d9c44",
     "grade": false,
     "grade_id": "cell-21490e58b10fdc96",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### create a dictionary where keys will be categories & sub-categories as values. store in inside Category_dict.\n",
    "\n",
    "def cat_dict(data,main_col,sub_col):    \n",
    "    Category_dict = {}\n",
    "    for index, row in data.iterrows():\n",
    "        if not pd.isna(row[main_col]) and not pd.isna(row[sub_col]):\n",
    "            Category_dict[row[main_col]] = Category_dict.get(row[main_col], []) + [row[sub_col]]\n",
    "    return Category_dict\n",
    "\n",
    "def category_subcategory_map_dataframe(df, Category_dict, main_col, sub_col):\n",
    "    def category_subcategory_map(row):\n",
    "        if pd.isna(row[main_col]):  # If the main column is null\n",
    "            if not pd.isna(row[sub_col]):  # If the sub column is not null\n",
    "                for k, v in Category_dict.items():\n",
    "                    if row[sub_col] in Category_dict[k]:\n",
    "                        return k  # k is the correct sector for the category value v\n",
    "        else:\n",
    "            return row[main_col]  # If the main column is not null, return its existing value\n",
    "\n",
    "    df[main_col] = df.apply(category_subcategory_map, axis=1)\n",
    "    return df[main_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca13699d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04770eb18fbe738071a15e5ed444f3cc",
     "grade": false,
     "grade_id": "cell-9da1ee987db9921e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Category_dict=cat_dict(data=sales,main_col='category',sub_col='sub_category')\n",
    "sales['category']=category_subcategory_map_dataframe(df=sales, Category_dict=Category_dict, main_col='category', sub_col='sub_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.category.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6f265",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f19e9fdeb5412b2ef75e71671a2bded",
     "grade": true,
     "grade_id": "cell-b7f7ba970eee54ec",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4c1a53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83ab0c15388879947cd4a98fa8b60e0a",
     "grade": false,
     "grade_id": "cell-36100bb51db5d5ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.3 ) Fill the missing values in sales column by mean. Return output series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2f9aa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7877d8d6c50f31fec6f085bfa4a773e",
     "grade": false,
     "grade_id": "cell-7ef02c9d67c20af2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fill_missing(data,col):\n",
    "    mean_value = data[col].mean()\n",
    "    data[col] = data[col].fillna(mean_value)\n",
    "    return data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee98bc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0274ee6bba9a9b563552ac701b154a00",
     "grade": false,
     "grade_id": "cell-bd5acc23dda57e56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['sales']=fill_missing(data=sales,col='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea47e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.sales.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf2a3a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b181ccfcb48887704a60854b4ad6f67e",
     "grade": true,
     "grade_id": "cell-519682f18719b5ec",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca6e3f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "013fe68074095516764de26176498a6f",
     "grade": false,
     "grade_id": "cell-efe9345bbfb4eca0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.4 ) How many orders have sales falling in the following groups \n",
    "Groups :- [0,12),[12,37),[37,113),[113,186),[186,1200),[1200,max).\n",
    "\n",
    "**Note :-[a,b) indicates that bin includes a but excudes b]**\n",
    "\n",
    "**Return output series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6667d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[\"sales\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb15f6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78ec9b1d010ea1ddd4140a78214fe242",
     "grade": false,
     "grade_id": "cell-011ab56604d6dc6d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def manual_bin(data,col):\n",
    "    # Define the bin edges\n",
    "    bins = [0, 12, 37, 113, 186, 1200, float('inf')]\n",
    "    \n",
    "    # Use the cut function to categorize 'sales' into the specified bins\n",
    "    data['bin'] = pd.cut(data[col], bins, right=False)\n",
    "    \n",
    "    # Use value_counts to count the number of orders in each bin\n",
    "    bin_counts = data['bin'].value_counts().sort_index()\n",
    "\n",
    "    # Reset the index to have a clean output series\n",
    "    bin_counts = bin_counts.reset_index()\n",
    "\n",
    "    # Rename the columns for clarity\n",
    "    # bin_counts.columns = ['Sales Range', 'Number of Orders']\n",
    "    bin_counts = pd.Series(data=bin_counts[\"bin\"])\n",
    "    \n",
    "    return bin_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778af290",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_bin(sales, \"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f10620",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a851078ccac72dcd296bcf43bdeb4af3",
     "grade": true,
     "grade_id": "cell-c70daab6a00fb4e5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(manual_bin(data=sales,col='sales'))==pd.Series, \"Please provide output in series format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f0e0db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ebe6caa6ff2cd58de70b6d13686395e",
     "grade": true,
     "grade_id": "cell-5553c36ce34800ac",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9481c59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e659cd2add50a5e6a9b26451da2da00c",
     "grade": false,
     "grade_id": "cell-411ca83596683bbc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.5 )  Sometimes, it is difficult to comprehend the sales value as a numeric value. So, the business team wants to observe the sales as Low, Medium and High categories.  Write a code to discretize the sales data and  return a series containing Low, Medium and High with the respective number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae7995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.quantity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975a189",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8f1c2e00fe94b07f512ff25c65c2a2d",
     "grade": false,
     "grade_id": "cell-8e4399b1bccc98dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def discrete_bin(data,col):\n",
    "    # Define the bin edges and labels\n",
    "    bins = [1, 5, 10, 14]\n",
    "    labels = ['Low', 'Medium', 'High']\n",
    "    \n",
    "    # Use the cut function to categorize 'sales' into the specified bins and labels\n",
    "    data['category'] = pd.cut(data[col], bins, labels=labels)\n",
    "    \n",
    "    # Use value_counts to count the number of records in each category\n",
    "    category_counts = data['category'].value_counts().sort_index()\n",
    "    \n",
    "    # Reset the index to have a clean output series\n",
    "    category_counts = category_counts.reset_index()\n",
    "    \n",
    "    category_counts = pd.Series(data=category_counts[\"category\"])\n",
    "    \n",
    "    return category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab8a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_bin(sales,'quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26753575",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd91f8895a0a23e4c820c9e703bfaf14",
     "grade": true,
     "grade_id": "cell-8f418bc782917abb",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(discrete_bin(data=sales,col='quantity'))==pd.Series, \"Please provide output in series format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6956357",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87b88cc8469ffcf0d27feb6add9d7393",
     "grade": true,
     "grade_id": "cell-4a156f92f5438b15",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e911e05",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f2e603bd0624c8263b6e2a3068e49a5",
     "grade": false,
     "grade_id": "cell-bfaec051e6ec0804",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.6. In order to perform further analysis, we intend to utilize the 'order_priority' variable, which has categorical values ('First Class'(0) > 'Second Class'(1) > 'Standard Class'(2) > 'Same Day'(3)). To facilitate this analysis, we need to convert 'order_priority' into a numerical feature. Please encode 'order_priority' into a numerical format.Return output series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.ship_mode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998b2b7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ac8ef080a2fc7bddce6e19432d4be20",
     "grade": false,
     "grade_id": "cell-d684beb2bc73d5a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Select Appropriate priority\n",
    "\n",
    "priority= ['Standard Class', 'Second Class', 'First Class', 'Same Day']\n",
    "\n",
    "# Mapping dictionary to encode 'order_priority'\n",
    "order_priority_mapping = {\n",
    "    'Same Day': 3,\n",
    "    'First Class': 0,\n",
    "    'Second Class': 1,\n",
    "    'Standard Class': 2  }\n",
    "\n",
    "def transforming_ordered_var(data,col,priority,nan_val):\n",
    "    data[col] = data[col].map(order_priority_mapping)\n",
    "    data[col] = data[col].fillna(nan_val)\n",
    "    return data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec16b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforming_ordered_var(sales,'ship_mode',priority,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b11db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f6fbb82e21fc0a53b8752d7dca33c52",
     "grade": false,
     "grade_id": "cell-ad8777d7794dba8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['shipping_mode_encoded']=transforming_ordered_var(data=sales,col='ship_mode',priority=priority,nan_val=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a18545",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dced94818db59b117fe7ea7136c627d5",
     "grade": true,
     "grade_id": "cell-f1ba60c8543b3583",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47f283",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96946235ba1c31c69c5900a743fca30f",
     "grade": false,
     "grade_id": "cell-b6ebfb80fba185f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.8) Outliers can be defined in different ways. For each of the following definitions of outliers, what percent of the values in the  'sales' are considered outliers? Give the answer as a percent rounded upto two decimal places.\n",
    "\n",
    "Note -\n",
    "1. 'IQR_detection' : Less than (Q1 - 1.5*IQR) and greater than (Q3 + 1.5*IQR) are considered outliers\n",
    "\n",
    "2. 'percentile_detection': Below the 3rd percentile and above the 97th percentile are considered outliers\n",
    "\n",
    "3. 'mean_SD' : Less than (mean - 3*SD) and greater than (mean + 3*SD) are considered outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4203a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5ca19",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49f6cb7c6a41b6691e798a91c98b9487",
     "grade": false,
     "grade_id": "cell-c1830537e6d495e9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def detect_outliers(data,col,method):\n",
    "    if method=='IQR_detection':\n",
    "        # Calculate the first quartile (Q1) and the third quartile (Q3)\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        \n",
    "        # Calculate the interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Determine the lower and upper bounds for outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Count the number of outliers\n",
    "        outliers = (data[col] < lower_bound) | (data[col] > upper_bound)\n",
    "        \n",
    "    elif method=='percentile_detection':\n",
    "        \n",
    "        # Calculate the 3rd and 97th percentiles\n",
    "        percentile_3 = data[col].quantile(0.03)\n",
    "        percentile_97 = data[col].quantile(0.97)\n",
    "        \n",
    "        # Determine the lower and upper bounds for outliers\n",
    "        lower_bound = percentile_3\n",
    "        upper_bound = percentile_97\n",
    "        \n",
    "        # Count the number of outliers\n",
    "        outliers = (data[col] < lower_bound) | (data[col] > upper_bound)\n",
    "        \n",
    "    elif method=='mean_SD':\n",
    "        # Calculate the mean and standard deviation (SD)\n",
    "        mean = data[col].mean()\n",
    "        std_dev = data[col].std()\n",
    "        \n",
    "        # Determine the lower and upper bounds for outliers\n",
    "        lower_bound = mean - 3 * std_dev\n",
    "        upper_bound = mean + 3 * std_dev\n",
    "        \n",
    "        # Count the number of outliers\n",
    "        outliers = (data[col] < lower_bound) | (data[col] > upper_bound)\n",
    "        \n",
    "    outliers_perc = float((outliers.sum() / len(data[col])) * 100)\n",
    "    \n",
    "            \n",
    "    return outliers_perc\n",
    "\n",
    "# Assert the type of the output\n",
    "# assert type(detect_outliers(data=data['sales'], col='sales', method='IQR_detection')) == np.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445688a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_outliers(sales,'sales','IQR_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b47894",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adc1a3d9d1296b6e163ec79aae82b684",
     "grade": true,
     "grade_id": "cell-618cb2f39f3bdbb8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(detect_outliers(data=sales,col='sales',method='IQR_detection'))==np.float, 'Make sure that output is returned as float'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d641f820",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "614526cb94a6bb00fb40f88fa84198f3",
     "grade": true,
     "grade_id": "cell-bfd2679b1e2a3929",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70046e87",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcdbc184e80602e9434ffb6ec63f615c",
     "grade": false,
     "grade_id": "cell-7e2416cf00578a58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.10) Detect upper end outliers in profit column by 'IQR_detection'. Return number of upper end outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27047dd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efb1464ffea6ae09ca5f555613bdd556",
     "grade": false,
     "grade_id": "cell-96b2becd9fec86dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def detect_upperend_outliers(data,col):\n",
    "    \n",
    "    # Calculate the first quartile (Q1) and the third quartile (Q3)\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "        \n",
    "    # Calculate the interquartile range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "        \n",
    "    # Determine the lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "    # Count the number of outliers\n",
    "    upper_outliers = int((data[col] > upper_bound).sum())\n",
    "        \n",
    "    return upper_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e398d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_upperend_outliers(sales,'profit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7398dbe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53f5c3196b19cf7bb65c788d4fdaddb6",
     "grade": true,
     "grade_id": "cell-9623402867c6a9ef",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(detect_upperend_outliers(data=sales,col='profit'))==int , 'No of outliers should be an integer , make sure that you are returning output in integer format.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf8925",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "722b6e630ccd11fc4fe566309c0fff85",
     "grade": true,
     "grade_id": "cell-5e43e81906b9a713",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9832dd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "237b9c1a702099cf0ef5de527c073a4e",
     "grade": false,
     "grade_id": "cell-8439e3bd38ccbfe8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.11) Floor & Capping outliers at 97% at 3%. Return the processed column as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c191eb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2415fc7992d7cdaf6ad0b8f943766e04",
     "grade": false,
     "grade_id": "cell-f5527eddcb6c9757",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cap_and_floor_column(column, cap_percentile, floor_percentile):\n",
    "    # Calculate the 3rd and 97th percentiles\n",
    "    percentile_3 = column.quantile(0.03)\n",
    "    percentile_97 = column.quantile(0.97)\n",
    "        \n",
    "    # Determine the lower and upper bounds for outliers\n",
    "    lower_bound = percentile_3\n",
    "    upper_bound = percentile_97\n",
    "        \n",
    "    # Cap and floor the column based on the bounds\n",
    "    capped_and_floored_column = column.clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    return capped_and_floored_column ## Capped ,Floored series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a3c1d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "feca18bd11ab3ed3ecd96e098af13cd5",
     "grade": false,
     "grade_id": "cell-829558a407b31ac1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['profit_outlier_capped'] = cap_and_floor_column(column=sales['profit'], cap_percentile=97, floor_percentile=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['profit_outlier_capped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f10d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c516d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2f24af7a9c0a4f9cca886c67a1a54c0",
     "grade": true,
     "grade_id": "cell-e8e8dbefcd633180",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(np.quantile(sales['profit_outlier_capped'],0.97),4)==301.9693, 'Make sure that you are flooring and capping with correct percentiles & returning the correct output.'\n",
    "assert round(np.quantile(sales['profit_outlier_capped'],0.03),4)==-144.632, 'Make sure that you are flooring and capping with correct percentiles & returning the correct output.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b7e6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5d84b0162199560d09ec36ca921335c",
     "grade": true,
     "grade_id": "cell-d317f90221447667",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2106d2e2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f871a19be79e96940943e73a7e895a99",
     "grade": false,
     "grade_id": "cell-1f2690daaff6ede8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.12) Business team is interested in knowing how many vendors have profit_outlier_capped >10000 & vendors with profit_outlier_capped <10000. Return the dataframe with 3 columns vendor  , profit_outlier_capped , profit_bins & sort it with 'profit_outlier_capped' in descending order.\n",
    "\n",
    "Instructions:-\n",
    "1. Bins should be in (a,b] format. [a,b) indicates that bin includes a but excudes b])\n",
    "2. Make sure that for 1st interval it is **left inclusive** i.e [a,b].\n",
    "3. Segment the ''profit_outlier_capped'' variable in 2 bins. (first bin with profit>10000 ,second bin with profit<10000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ee1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.groupby(\"vendor\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two bins: one for profit > 10000 and one for profit <= 10000\n",
    "bins = [0, 10000, float('inf')]\n",
    "    \n",
    "# Create labels for the bins\n",
    "labels = ['<= 10000', '> 10000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed5658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'profit_bins' that segments 'profit_outlier_capped'\n",
    "sales['profit_bins'] = pd.cut(sales['profit_outlier_capped'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e67ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd522575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to include only 'vendor', 'profit_outlier_capped', and 'profit_bins' columns\n",
    "sales = sales[['vendor', 'profit_outlier_capped', 'profit_bins']]\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ad102",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['vendor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d2dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e32c21",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa43f93865c896afc8c640ba73478565",
     "grade": false,
     "grade_id": "cell-77f6b02474e37c07",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def profit_vendor(data,col):\n",
    "    # Create two bins: one for profit > 10000 and one for profit <= 10000\n",
    "    bins = [0, 10000, float('inf')]\n",
    "    \n",
    "    # Create labels for the bins\n",
    "    labels = ['<= 10000', '> 10000']\n",
    "    \n",
    "    # Create a new column 'profit_bins' that segments 'profit_outlier_capped'\n",
    "    data['profit_bins'] = pd.cut(data[col], bins=bins, labels=labels, right=False)\n",
    "    \n",
    "    # Filter the dataframe to include only 'vendor', 'profit_outlier_capped', and 'profit_bins' columns\n",
    "    data = data[['vendor', 'profit_outlier_capped', 'profit_bins']]\n",
    "    \n",
    "    # Drop duplicate values in the 'vendor' column to make it distinct\n",
    "    data['vendor'] = data['vendor'].drop_duplicates()\n",
    "    \n",
    "        \n",
    "    # Reset the index to have a clean result\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Sort the dataframe by 'profit_outlier_capped' in descending order\n",
    "    data = data.sort_values(by='profit_outlier_capped', ascending=False)\n",
    "    \n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b1cdba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61d102d505d0f1a719c864515d6e3cfb",
     "grade": true,
     "grade_id": "cell-e3d429861a4da377",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(profit_vendor(data=sales,col='profit_outlier_capped'))==pd.DataFrame ,'Make sure that your output is a dataframe '\n",
    "assert profit_vendor(data=sales,col='profit_outlier_capped').shape==(65,3) ,'Make sure that shape of your dataframe is correct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287c82df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05fe6b290e535e2b20d3333725f36653",
     "grade": true,
     "grade_id": "cell-05010ee8edfc15a7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27af271",
   "metadata": {},
   "source": [
    "#  55/100 points earned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b1036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ac61846",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
