{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aead60dbe4aab181e67a59dcec087c6b",
     "grade": false,
     "grade_id": "cell-863e01b9f03e4a8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Graded Lab 4\n",
    "\n",
    "Hello ! Welcome to Graded Lab of Module 4.\n",
    "\n",
    "In the last assignment we had worked on correlation , hypothesis which business wanted us to test.\n",
    "Its high time when we look at the missing values & outliers stuff.\n",
    "**Here we will work on missing values & outliers.**\n",
    "\n",
    "In case if you are not able to recollect the problem description and data description then mentioning it below.\n",
    "\n",
    "Lets look at the problem statement,\n",
    "\n",
    "*Client: ABC Retail, Incorporated, rest-of-the-world division* \n",
    "\n",
    "***Project name: Online retail sales analysis*** \n",
    "\n",
    "An online retailer, ABC, Inc., operates in nearly 100 countries worldwide, selling furniture, office supplies and technology products to customers in three segments: consumer, corporate and home office. ABC, Inc. is a US-based company, and it has two major divisions: US and rest of the world. We are working with the rest of the world division of the company. \n",
    "\n",
    "They have provided us with online sales transaction data from 2011 to 2014.\n",
    "\n",
    "We are given 3 datasets:-\n",
    "\n",
    "1. Data on each sale; 51290 records; all data in US dollars\n",
    "It contains fields like\n",
    "**order_id** (identifier) ,order_date ,ship_date ,ship_mode ,**customer_id**(identifier) ,product_id ,category ,sub_category ,product_name ,sales ,quantity ,discount ,profit ,shipping_cost ,order_priority ,**vendor_code** (identifier) \n",
    "\n",
    "\n",
    "2. Data on the customers; 1590 records \n",
    "It contains fields like\n",
    "**customer_id** (identifier) ,customer_name ,city ,state ,country ,postal_code ,segment ,market ,region \n",
    "\n",
    "3. Data on vendors who supply the retailer; 65 records \n",
    "It contains fields like\n",
    "vendor ,**vendor_code** (identifier) \n",
    "\n",
    "We need to analyze the data and need to provide answer to different questions asked by company officials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor update: Jan 29, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7442207fb33a683cc6602a682d1c108",
     "grade": false,
     "grade_id": "cell-ed16b8e1f54252ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>ship_date</th>\n",
       "      <th>ship_mode</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>product_name</th>\n",
       "      <th>sales</th>\n",
       "      <th>quantity</th>\n",
       "      <th>discount</th>\n",
       "      <th>profit</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>order_priority</th>\n",
       "      <th>vendor_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MX-2014-143658</td>\n",
       "      <td>02/10/2014</td>\n",
       "      <td>06/10/2014</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SC-20575</td>\n",
       "      <td>OFF-LA-10002782</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Hon File Folder Labels, Adjustable</td>\n",
       "      <td>13.08</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.56</td>\n",
       "      <td>1.03</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>FUR-FU-10004015</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furnishings</td>\n",
       "      <td>Tenex Clock, Durable</td>\n",
       "      <td>252.16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.72</td>\n",
       "      <td>13.45</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>FUR-BO-10002352</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Ikea 3-Shelf Cabinet, Mobile</td>\n",
       "      <td>193.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.08</td>\n",
       "      <td>9.63</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>OFF-BI-10004428</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Binders</td>\n",
       "      <td>Cardinal Binder, Clear</td>\n",
       "      <td>35.44</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.96</td>\n",
       "      <td>1.37</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>OFF-AR-10004594</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Art</td>\n",
       "      <td>Sanford Canvas, Water Color</td>\n",
       "      <td>71.60</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.44</td>\n",
       "      <td>3.79</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id        order_id  order_date   ship_date       ship_mode customer_id  \\\n",
       "0       1  MX-2014-143658  02/10/2014  06/10/2014  Standard Class    SC-20575   \n",
       "1       2  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "2       3  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "3       4  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "4       5  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "\n",
       "        product_id         category sub_category  \\\n",
       "0  OFF-LA-10002782  Office Supplies       Labels   \n",
       "1  FUR-FU-10004015        Furniture  Furnishings   \n",
       "2  FUR-BO-10002352        Furniture    Bookcases   \n",
       "3  OFF-BI-10004428  Office Supplies      Binders   \n",
       "4  OFF-AR-10004594  Office Supplies          Art   \n",
       "\n",
       "                         product_name   sales  quantity  discount  profit  \\\n",
       "0  Hon File Folder Labels, Adjustable   13.08         3       0.0    4.56   \n",
       "1                Tenex Clock, Durable  252.16         8       0.0   90.72   \n",
       "2        Ikea 3-Shelf Cabinet, Mobile  193.28         2       0.0   54.08   \n",
       "3              Cardinal Binder, Clear   35.44         4       0.0    4.96   \n",
       "4         Sanford Canvas, Water Color   71.60         2       0.0   11.44   \n",
       "\n",
       "   shipping_cost order_priority vendor_code  \n",
       "0           1.03         Medium      VE_001  \n",
       "1          13.45         Medium      VE_002  \n",
       "2           9.63         Medium      VE_003  \n",
       "3           1.37         Medium      VE_004  \n",
       "4           3.79         Medium      VE_005  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "### Reading sales data\n",
    "sales = pd.read_csv('sales_data_M4.csv')\n",
    "\n",
    "### Reading customer data\n",
    "cust = pd.read_csv(r'customers.csv',encoding='iso-8859-1')\n",
    "\n",
    "### Reading vendor data\n",
    "vend = pd.read_csv(r'vendors.csv')\n",
    "\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "868201adf0e3beea45c39e2a4849188a",
     "grade": false,
     "grade_id": "cell-78efe7e0424ff809",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In order to solve the next questions , we need to combine all the 3 datasets into a single dataframe such that every details of sales dataframe are intact. So here we have written a data processing function.\n",
    "There are 2 tasks which are to be performed.\n",
    "1. Merge/ Join all the 3 datasets into a single dataframe such that every details of sales dataframe are intact. (Understand which should be the joining key , type of join , refer .merge() function of pandas)\n",
    "2. Convert 'order_date' into a datetime column.\n",
    "**Return output as a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fce96ba65cc5a5db25571a75d2347ca",
     "grade": false,
     "grade_id": "cell-760043ec960a09cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#### data_merging & order_date processing , data1 will be sales , data2 will be customer dataset & data3 will be vendor dataset.\n",
    "\n",
    "def data_process(data1,data2,data3):\n",
    "    \n",
    "    # Merge data1 and data2 on 'customer_id'\n",
    "\n",
    "    data = pd.merge(data1, data2, on='customer_id', how='left')\n",
    "\n",
    "    # Merge the result with data3 on 'vendor_code'\n",
    "\n",
    "    data = pd.merge(data, data3, on='vendor_code', how='left')\n",
    "\n",
    "    # Convert 'order_date' into a datetime column\n",
    "\n",
    "    data['order_date'] = pd.to_datetime(data['order_date'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33f7110cf96724cd31f65c6ce99f3e4c",
     "grade": false,
     "grade_id": "cell-e8c25b222f675992",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales= data_process(data1=sales.copy(),data2=cust.copy(),data3=vend.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a67642ea4eef0f94a4e3a46a6081afa1",
     "grade": true,
     "grade_id": "cell-24e204e9afc2c313",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sales['order_date'].dtypes=='<M8[ns]' ,'Make sure if you have converted order_date into a datetime format correctly or not.'\n",
    "assert sales.shape== (51290,26) ,'Checking size and shape of dataframe after merging is a very important check.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['order_date'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51290, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales.to_csv(\"salesmissing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbdd9d97abd1fb4a8fc6b22845b5307a",
     "grade": false,
     "grade_id": "cell-7e22460af514a787",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that in this dataset we are purposefully introducing some of the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f03011a88731ed4f047dfbfbc7e6b1c",
     "grade": false,
     "grade_id": "cell-867679f736a58367",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.1 Return column names & missing values percentage for the columns which has missing value% >50. Output should be a dictionary. \n",
    "\n",
    "For eg:- { column_name : value%} i.e {'A':54.50,'B':59.75}, make sure to round off percentages to 2 decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "228f97ed1aabf7db12d62ccf5d29527c",
     "grade": false,
     "grade_id": "cell-eaa4ef1cb3c93902",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def missing_value_col(data):\n",
    "    \n",
    "    # Calculate the percentage of missing values for each column\n",
    "    missing_percentages = data.isnull().mean() * 100\n",
    "\n",
    "    # Filter out columns which have more than 50% missing values\n",
    "    missing_percentages = {col: round(percent, 2) for col, percent in missing_percentages.items() if percent > 50}\n",
    "\n",
    "    return missing_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b039c79284e4b99a00fda192a26f4d9f",
     "grade": true,
     "grade_id": "cell-6d0d4c99764805c4",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'postal_code': 100.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_col(data=sales) ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb8633889e246a9d9cda5f41cf0770e7",
     "grade": false,
     "grade_id": "cell-00e1cff3e5f47a7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### **Senior data scientists after consulting with the business have decided that such columns needs to be dropped before going further.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "daeeadeee84f44971acd919fd87992ed",
     "grade": false,
     "grade_id": "cell-26857c8737cf80a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "high_missing_col=list(missing_value_col(data=sales).keys()) #Enter the columns with high % of missing values\n",
    "### We will drop columns with such high missing values\n",
    "sales.drop(high_missing_col,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51290, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c96de899447751e3edc9661326e762bb",
     "grade": false,
     "grade_id": "cell-e795cfc2b6847586",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.2 Fill the missing data in 'category' column with appropriate method.  \n",
    "(Hint:- Remember variable 'category' & 'sub-category' are related & hierachy goes like this category -> sub-category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7161528af2accdb5397c22ff972ec375",
     "grade": false,
     "grade_id": "cell-e10cc0483013a3f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Approach:-\n",
    "\n",
    "1. Create a key-pair dictionary where key will be product category & pair values will be sub-categories.\n",
    "\n",
    "2. Wherever category value is missing check for corresponding sub-category value. \n",
    "\n",
    "3. From sub-category value trace back its original product category value by looking in dictionary, get a product value.\n",
    "\n",
    "4. Fill the blank product category value by the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5228a1362ce2d6e881abec02af1302b0",
     "grade": false,
     "grade_id": "cell-21490e58b10fdc96",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### create a dictionary where keys will be categories & sub-categories as values. store in inside Category_dict.\n",
    "\n",
    "def cat_dict(data,main_col,sub_col):\n",
    "    \n",
    "    # Create a dictionary where keys are categories and values are lists of sub-categories\n",
    "    Category_dict = data.groupby(main_col)[sub_col].apply(list).to_dict()\n",
    "    # Remove duplicates in each list\n",
    "    Category_dict = {k: list(set(v)) for k, v in Category_dict.items()}\n",
    "    return Category_dict \n",
    "\n",
    "def category_subcategory_map_dataframe(df, Category_dict, main_col, sub_col):\n",
    "    def category_subcategory_map(row):\n",
    "        if pd.isna(row[main_col]):  # If the main column is null\n",
    "            if not pd.isna(row[sub_col]):  # If the sub column is not null\n",
    "                for k, v in Category_dict.items():\n",
    "                    if row[sub_col] in Category_dict[k]:\n",
    "                        return k  # k is the correct sub-category for the category value v\n",
    "        else:\n",
    "            return row[main_col]  # If the main column is not null, return its existing value\n",
    "\n",
    "    df[main_col] = df.apply(category_subcategory_map, axis=1)\n",
    "    return df[main_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04770eb18fbe738071a15e5ed444f3cc",
     "grade": false,
     "grade_id": "cell-9da1ee987db9921e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Category_dict=cat_dict(data=sales,main_col='category',sub_col='sub_category')\n",
    "sales['category']=category_subcategory_map_dataframe(df=sales, Category_dict=Category_dict, main_col='category', sub_col='sub_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b67901d4b9c73d7452f398b343755b10",
     "grade": true,
     "grade_id": "cell-b7f7ba970eee54ec",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Office Supplies\n",
       "1              Furniture\n",
       "2              Furniture\n",
       "3        Office Supplies\n",
       "4        Office Supplies\n",
       "              ...       \n",
       "51285    Office Supplies\n",
       "51286         Technology\n",
       "51287    Office Supplies\n",
       "51288    Office Supplies\n",
       "51289    Office Supplies\n",
       "Name: category, Length: 51290, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['category']  ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0281cb5d325a1ddad1e817939aa53bf",
     "grade": false,
     "grade_id": "cell-36100bb51db5d5ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.3 ) Fill the missing values in 'sales' column by average value of that column. Return output series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7877d8d6c50f31fec6f085bfa4a773e",
     "grade": false,
     "grade_id": "cell-7ef02c9d67c20af2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fill_missing(data,col):\n",
    "    \n",
    "    # Calculate the mean of the column\n",
    "    mean_val = data[col].mean()\n",
    "    \n",
    "    # Fill missing values with the mean\n",
    "    data[col] = data[col].fillna(mean_val)\n",
    "\n",
    "    return data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0274ee6bba9a9b563552ac701b154a00",
     "grade": false,
     "grade_id": "cell-bd5acc23dda57e56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['sales']=fill_missing(data=sales,col='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad866947de141d47963c930462345599",
     "grade": true,
     "grade_id": "cell-519682f18719b5ec",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert sales['sales'].isna().sum()==0 ,'Missing values found for sales.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['sales'].isna().sum() ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f84bc5ec9ad01f6ca448f1680063a12",
     "grade": false,
     "grade_id": "cell-efe9345bbfb4eca0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.4 ) Discretize the 'sales' column wrto following groups. Each group should contain number of orders as values.\n",
    "Groups :- [0,12),[12,37),[37,113),[113,186),[186,1200).\n",
    "\n",
    "**Note :-[a,b) indicates that group includes a but excudes b.**\n",
    "\n",
    "**Return output series with group name as index & number of orders as values.**\n",
    "\n",
    "For eg:-\n",
    "\n",
    "[186, 1200)             123\n",
    "\n",
    "[37, 113)               123\n",
    "\n",
    "[12, 37)                123\n",
    "\n",
    "[113, 186)              123\n",
    "\n",
    "[0, 12)                 123\n",
    "\n",
    "Name: sales, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78ec9b1d010ea1ddd4140a78214fe242",
     "grade": false,
     "grade_id": "cell-011ab56604d6dc6d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def manual_bin(data,col):\n",
    "    \n",
    "    # Define the bin edges\n",
    "    bins = [0, 12, 37, 113, 186, 1200]\n",
    "    \n",
    "    # Use pandas cut function to bin the data\n",
    "    bins_result = pd.cut(data[col], bins, right=False)\n",
    "    \n",
    "    # Use value_counts to count the number of orders in each bin, then sort by values in descending order\n",
    "    result_series = bins_result.value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    return result_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a851078ccac72dcd296bcf43bdeb4af3",
     "grade": true,
     "grade_id": "cell-c70daab6a00fb4e5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(manual_bin(data=sales,col='sales'))==pd.Series, \"Please provide output in series format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8923ae6d85b3f5fbf148ed1b35e510ef",
     "grade": true,
     "grade_id": "cell-5553c36ce34800ac",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert manual_bin(data=sales,col='sales').values[0]==18550, 'Make sure you have returned correct series values.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[186, 1200)    18550\n",
       "[37, 113)      12761\n",
       "[12, 37)        9325\n",
       "[113, 186)      5187\n",
       "[0, 12)         3708\n",
       "Name: sales, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_bin(data=sales,col='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(manual_bin(data=sales,col='sales'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18550"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_bin(data=sales,col='sales').values[0]  ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11a0bd7d960e1c33273cf3cf15172651",
     "grade": false,
     "grade_id": "cell-411ca83596683bbc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.5 )  Sometimes, it is difficult to comprehend the quantity sold ('quantity') value as a numeric value. So, the business team wants to observe the sales as High, Medium and Low categories.  \n",
    "\n",
    "### Write a code to discretize the sales data and  return an output series containing High, Medium and Low categories as index & the respective number of records as values.\n",
    "\n",
    "Hint : Here the bounds for High , Medium , Low categories are not given hence we can consider the equal split of data for defining the bounds , think of using pd.cut() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8f1c2e00fe94b07f512ff25c65c2a2d",
     "grade": false,
     "grade_id": "cell-8e4399b1bccc98dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# def discrete_bin(data,col):\n",
    "    \n",
    "#     # Define the bins for High, Medium, and Low\n",
    "#     bins = [float('-inf'), data[col].quantile(1/3), data[col].quantile(2/3), float('inf')]\n",
    "    \n",
    "#     # Define the labels for the bins\n",
    "#     labels = ['Low', 'Medium', 'High']\n",
    "    \n",
    "#     # Cut the 'quantity' column into bins\n",
    "#     bins_result = pd.cut(data[col], bins=bins, labels=labels, include_lowest=True, right=False)\n",
    "    \n",
    "#     # Count the number of records in each category\n",
    "#     result_series = bins_result.value_counts().sort_index(ascending=False)\n",
    "    \n",
    "#     return result_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_bin(data, col):\n",
    "    \n",
    "    bins = pd.cut(data[col], bins=3, labels=['Low', 'Medium', 'High'])\n",
    "    return bins.value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd91f8895a0a23e4c820c9e703bfaf14",
     "grade": true,
     "grade_id": "cell-8f418bc782917abb",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(discrete_bin(data=sales,col='quantity'))==pd.Series, \"Please provide output in series format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ac7df9091a243e222b2137186f31e5c",
     "grade": true,
     "grade_id": "cell-4a156f92f5438b15",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "High        877\n",
       "Medium     7753\n",
       "Low       42660\n",
       "Name: quantity, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_bin(data=sales,col='quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(discrete_bin(data=sales,col='quantity')) ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69180ffcbfb2f3db5b71648b49d61ec5",
     "grade": false,
     "grade_id": "cell-bfaec051e6ec0804",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.6. In order to perform further analysis, we intend to utilize the 'ship_mode' variable, which has categorical values ('First Class'(0) > 'Second Class'(1) > 'Standard Class'(2) > 'Same Day'(3)). To facilitate this analysis, we need to convert 'ship_mode' into a numerical feature. Please encode 'ship_mode' into a numerical format.\n",
    "### Return output series.\n",
    "\n",
    "Hint : Think of using the OrdinalEncoder() function from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9f7fd1f616030f79a13ddce6e0c1aaa",
     "grade": false,
     "grade_id": "cell-d684beb2bc73d5a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Select Appropriate priority\n",
    "\n",
    "priority = {'First Class': 0, 'Second Class': 1, 'Standard Class': 2, 'Same Day': 3}\n",
    "\n",
    "def transforming_ordered_var(data,col,priority,nan_val):\n",
    "    #data: dataset to be used\n",
    "    #col : column name which is to be encoded.\n",
    "    #priority: list of categories sorted from highest order of importance to lowest order importance.\n",
    "    #nan_val : it will be a value assigned in place of nan's.   \n",
    "    data[col] = data[col].map(priority).fillna(nan_val).astype(int)\n",
    "\n",
    "    return data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f6fbb82e21fc0a53b8752d7dca33c52",
     "grade": false,
     "grade_id": "cell-ad8777d7794dba8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['shipping_mode_encoded']=transforming_ordered_var(data=sales,col='ship_mode',priority=priority,nan_val=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "990ca39a1d441a055ef5ef6883da3868",
     "grade": true,
     "grade_id": "cell-f1ba60c8543b3583",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert int(sales['shipping_mode_encoded'].value_counts().loc[lambda x:x.index==5])==1570"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        2\n",
       "2        2\n",
       "3        2\n",
       "4        2\n",
       "        ..\n",
       "51285    0\n",
       "51286    5\n",
       "51287    0\n",
       "51288    0\n",
       "51289    2\n",
       "Name: shipping_mode_encoded, Length: 51290, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['shipping_mode_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    29842\n",
       "1     9985\n",
       "0     7272\n",
       "3     2621\n",
       "5     1570\n",
       "Name: shipping_mode_encoded, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['shipping_mode_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1570\n",
       "Name: shipping_mode_encoded, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['shipping_mode_encoded'].value_counts().loc[lambda x:x.index==5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d359c61c53aec27e414687a8ac48db46",
     "grade": false,
     "grade_id": "cell-b6ebfb80fba185f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.7) Outliers can be defined in different ways. For each of the following definitions of outliers, what percent of the values in the  'sales' are considered outliers? Give the answer as a percent rounded upto two decimal places.\n",
    "\n",
    "\n",
    "Note -\n",
    "1. 'IQR_detection' : Less than (Q1 - 1.5*IQR) and greater than (Q3 + 1.5*IQR) are considered outliers\n",
    "\n",
    "2. 'percentile_detection': Below the 3rd percentile and above the 97th percentile are considered outliers\n",
    "\n",
    "3. 'mean_SD' : Less than (mean - 3*SD) and greater than (mean + 3*SD) are considered outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49f6cb7c6a41b6691e798a91c98b9487",
     "grade": false,
     "grade_id": "cell-c1830537e6d495e9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def detect_outliers(data,col,method):\n",
    "    \n",
    "    if method=='IQR_detection':\n",
    "        # Calculate the first quartile (Q1) and the third quartile (Q3)\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        \n",
    "        # Calculate the interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Determine the lower and upper bounds for outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Count the number of outliers\n",
    "        outliers = (data[col] < lower_bound) | (data[col] > upper_bound)\n",
    "        \n",
    "    elif method=='percentile_detection':\n",
    "        \n",
    "        # Calculate the 3rd and 97th percentiles\n",
    "        percentile_3 = data[col].quantile(0.03)\n",
    "        percentile_97 = data[col].quantile(0.97)\n",
    "        \n",
    "        # Determine the lower and upper bounds for outliers\n",
    "        lower_bound = percentile_3\n",
    "        upper_bound = percentile_97\n",
    "        \n",
    "        # Count the number of outliers\n",
    "        outliers = (data[col] < lower_bound) | (data[col] > upper_bound)\n",
    "        \n",
    "    elif method=='mean_SD':\n",
    "        # Calculate the mean and standard deviation (SD)\n",
    "        mean = data[col].mean()\n",
    "        std_dev = data[col].std()\n",
    "        \n",
    "        # Determine the lower and upper bounds for outliers\n",
    "        lower_bound = mean - 3 * std_dev\n",
    "        upper_bound = mean + 3 * std_dev\n",
    "        \n",
    "        # Count the number of outliers\n",
    "        outliers = (data[col] < lower_bound) | (data[col] > upper_bound)\n",
    "        \n",
    "    outliers_perc = float((outliers.sum() / len(data[col])) * 100)\n",
    "    \n",
    "    outliers_perc = round(outliers_perc,2)\n",
    "            \n",
    "    return outliers_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96a2e1afae09caded34b194190da2bb3",
     "grade": true,
     "grade_id": "cell-618cb2f39f3bdbb8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(detect_outliers(data=sales,col='sales',method='IQR_detection'))==np.float, 'Make sure that output is returned as float'\n",
    "assert detect_outliers(data=sales,col='sales',method='IQR_detection')==10.06, 'Make sure that output is rounded upto 2 decimals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfe0831685aec0a21f085c572cd43819",
     "grade": true,
     "grade_id": "cell-bfd2679b1e2a3929",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.06"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_outliers( data=sales, col='sales', method='IQR_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(detect_outliers(data=sales,col='sales',method='IQR_detection')) ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "523c3ad2a07309fff5c79a06ee1a45d8",
     "grade": false,
     "grade_id": "cell-7e2416cf00578a58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.8) Detect upper end outliers in profit column by 'IQR_detection'. Return number of upper end outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96dce0bf60982bde96370b12aa72fbbe",
     "grade": false,
     "grade_id": "cell-96b2becd9fec86dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def detect_upperend_outliers(data,col):\n",
    "    \n",
    "    # Calculate the first quartile (Q1) and the third quartile (Q3)\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "        \n",
    "    # Calculate the interquartile range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "        \n",
    "    # Determine the lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "    # Count the number of outliers\n",
    "    upper_outliers = int((data[col] > upper_bound).sum())\n",
    "        \n",
    "    return upper_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53f5c3196b19cf7bb65c788d4fdaddb6",
     "grade": true,
     "grade_id": "cell-9623402867c6a9ef",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(detect_upperend_outliers(data=sales,col='profit'))==int , 'No of outliers should be an integer , make sure that you are returning output in integer format.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51f68f5109a4586e177bdb8e25237654",
     "grade": true,
     "grade_id": "cell-5e43e81906b9a713",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6229"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_upperend_outliers(data=sales,col='profit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(detect_upperend_outliers(data=sales,col='profit'))  ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d2b8817299cd482a64d2e1cc6455a21",
     "grade": false,
     "grade_id": "cell-8439e3bd38ccbfe8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.9) Cap & Floor outliers at 97% at 3%. Return the processed column as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2415fc7992d7cdaf6ad0b8f943766e04",
     "grade": false,
     "grade_id": "cell-f5527eddcb6c9757",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cap_and_floor_column(column, cap_percentile, floor_percentile):\n",
    "    \n",
    "    # Calculate the 3rd and 97th percentiles\n",
    "    percentile_3 = column.quantile(0.03)\n",
    "    percentile_97 = column.quantile(0.97)\n",
    "        \n",
    "    # Determine the lower and upper bounds for outliers\n",
    "    lower_bound = percentile_3\n",
    "    upper_bound = percentile_97\n",
    "        \n",
    "    # Cap and floor the column based on the bounds\n",
    "    capped_and_floored_column = column.clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    return capped_and_floored_column ## Capped ,Floored series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "feca18bd11ab3ed3ecd96e098af13cd5",
     "grade": false,
     "grade_id": "cell-829558a407b31ac1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['profit_outlier_capped'] = cap_and_floor_column(column=sales['profit'], cap_percentile=97, floor_percentile=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2f24af7a9c0a4f9cca886c67a1a54c0",
     "grade": true,
     "grade_id": "cell-e8e8dbefcd633180",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(np.quantile(sales['profit_outlier_capped'],0.97),4)==301.9693, 'Make sure that you are flooring and capping with correct percentiles & returning the correct output.'\n",
    "assert round(np.quantile(sales['profit_outlier_capped'],0.03),4)==-144.632, 'Make sure that you are flooring and capping with correct percentiles & returning the correct output.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24e3e36e708f7ad06b95792cc36bb53c",
     "grade": true,
     "grade_id": "cell-d317f90221447667",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301.9693068"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(sales['profit_outlier_capped'],0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-144.6319602"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(sales['profit_outlier_capped'],0.03)  ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bca1b3367649c7a4eaac50143be6a3a",
     "grade": false,
     "grade_id": "cell-1f2690daaff6ede8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.10) Business team is interested in knowing how many vendors have profit_outlier_capped <10000 & vendors with profit_outlier_capped >10000. Return the dataframe with 3 columns vendor  , profit_outlier_capped , profit_bins & sort it with 'profit_outlier_capped' in descending order.\n",
    "\n",
    "Instructions:-\n",
    "1. Bins should be in (a,b] format. (a,b] indicates that bin excludes a but incudes b.\n",
    "2. Make sure that for **1st interval only** it should be **left inclusive** i.e [a,b].\n",
    "3. Segment the ''profit_outlier_capped'' variable in 2 bins. (binendpoints should be min value of profit<10000,10000,max value of profit>10000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa43f93865c896afc8c640ba73478565",
     "grade": false,
     "grade_id": "cell-77f6b02474e37c07",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def profit_vendor(data,col):\n",
    "    \n",
    "    # Group by vendor and calculate the sum of profit_outlier_capped\n",
    "    salesgrp = data.groupby(\"vendor\", as_index=False)[col].sum()\n",
    "\n",
    "    # Define bin cut-points\n",
    "    bin_cut_points = [salesgrp[col].min(), 10000, salesgrp[col].max()]\n",
    "\n",
    "    # Create profit_bins column using cut\n",
    "    salesgrp['profit_bins'] = pd.cut(salesgrp[col], bins=bin_cut_points, include_lowest=True, right=True)\n",
    "\n",
    "    # Sort the DataFrame by 'profit_outlier_capped' in descending order\n",
    "    salesgrp = salesgrp.sort_values(by=col, ascending=False)\n",
    "\n",
    "    return salesgrp[['vendor', col, 'profit_bins']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfbac0f852de806efc9ee1d60dd4f4fe",
     "grade": true,
     "grade_id": "cell-e3d429861a4da377",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(profit_vendor(data=sales,col='profit_outlier_capped'))==pd.DataFrame ,'Make sure that your output is a dataframe '\n",
    "assert str(profit_vendor(data=sales,col='profit_outlier_capped')['profit_bins'].unique()[0])=='(10000.0, 76469.853]' , 'Make sure that you are selecting bin cut-points(a & b) properly'\n",
    "assert str(profit_vendor(data=sales,col='profit_outlier_capped')['profit_bins'].unique()[1])=='(2732.9049999999997, 10000.0]', 'Make sure that you are selecting bin cut-points(a & b) properly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89928dfd8d4f37b0488a0d03c1ee4dab",
     "grade": true,
     "grade_id": "cell-05010ee8edfc15a7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor</th>\n",
       "      <th>profit_outlier_capped</th>\n",
       "      <th>profit_bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Proton Solutions</td>\n",
       "      <td>76469.85264</td>\n",
       "      <td>(10000.0, 76469.853]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Low Tide Corp</td>\n",
       "      <td>51929.66308</td>\n",
       "      <td>(10000.0, 76469.853]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Venusystems</td>\n",
       "      <td>49741.37212</td>\n",
       "      <td>(10000.0, 76469.853]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Sharkfin Networks</td>\n",
       "      <td>47919.12612</td>\n",
       "      <td>(10000.0, 76469.853]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lemonetworks</td>\n",
       "      <td>45814.85148</td>\n",
       "      <td>(10000.0, 76469.853]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Moondustries</td>\n",
       "      <td>5287.96536</td>\n",
       "      <td>(2732.9049999999997, 10000.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Luckydream</td>\n",
       "      <td>5243.19210</td>\n",
       "      <td>(2732.9049999999997, 10000.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Prodintelligence</td>\n",
       "      <td>4747.80126</td>\n",
       "      <td>(2732.9049999999997, 10000.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apexman</td>\n",
       "      <td>4583.38326</td>\n",
       "      <td>(2732.9049999999997, 10000.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rushcorp</td>\n",
       "      <td>2732.90606</td>\n",
       "      <td>(2732.9049999999997, 10000.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               vendor  profit_outlier_capped                    profit_bins\n",
       "44   Proton Solutions            76469.85264           (10000.0, 76469.853]\n",
       "28      Low Tide Corp            51929.66308           (10000.0, 76469.853]\n",
       "59        Venusystems            49741.37212           (10000.0, 76469.853]\n",
       "53  Sharkfin Networks            47919.12612           (10000.0, 76469.853]\n",
       "26       Lemonetworks            45814.85148           (10000.0, 76469.853]\n",
       "..                ...                    ...                            ...\n",
       "31       Moondustries             5287.96536  (2732.9049999999997, 10000.0]\n",
       "29         Luckydream             5243.19210  (2732.9049999999997, 10000.0]\n",
       "43   Prodintelligence             4747.80126  (2732.9049999999997, 10000.0]\n",
       "5             Apexman             4583.38326  (2732.9049999999997, 10000.0]\n",
       "48           Rushcorp             2732.90606  (2732.9049999999997, 10000.0]\n",
       "\n",
       "[65 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit_vendor(data=sales,col='profit_outlier_capped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interval(10000.0, 76469.853, closed='right')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(profit_vendor(data=sales,col='profit_outlier_capped')['profit_bins'].unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interval(2732.9049999999997, 10000.0, closed='right')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(profit_vendor(data=sales,col='profit_outlier_capped')['profit_bins'].unique()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 80/100 points earned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
