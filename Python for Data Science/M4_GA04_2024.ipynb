{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0482e9d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aead60dbe4aab181e67a59dcec087c6b",
     "grade": false,
     "grade_id": "cell-863e01b9f03e4a8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Graded Lab 4\n",
    "\n",
    "Hello ! Welcome to Graded Lab of Module 4.\n",
    "\n",
    "In the last assignment we had worked on correlation , hypothesis which business wanted us to test.\n",
    "Its high time when we look at the missing values & outliers stuff.\n",
    "**Here we will work on missing values & outliers.**\n",
    "\n",
    "In case if you are not able to recollect the problem description and data description then mentioning it below.\n",
    "\n",
    "Lets look at the problem statement,\n",
    "\n",
    "*Client: ABC Retail, Incorporated, rest-of-the-world division* \n",
    "\n",
    "***Project name: Online retail sales analysis*** \n",
    "\n",
    "An online retailer, ABC, Inc., operates in nearly 100 countries worldwide, selling furniture, office supplies and technology products to customers in three segments: consumer, corporate and home office. ABC, Inc. is a US-based company, and it has two major divisions: US and rest of the world. We are working with the rest of the world division of the company. \n",
    "\n",
    "They have provided us with online sales transaction data from 2011 to 2014.\n",
    "\n",
    "We are given 3 datasets:-\n",
    "\n",
    "1. Data on each sale; 51290 records; all data in US dollars\n",
    "It contains fields like\n",
    "**order_id** (identifier) ,order_date ,ship_date ,ship_mode ,**customer_id**(identifier) ,product_id ,category ,sub_category ,product_name ,sales ,quantity ,discount ,profit ,shipping_cost ,order_priority ,**vendor_code** (identifier) \n",
    "\n",
    "\n",
    "2. Data on the customers; 1590 records \n",
    "It contains fields like\n",
    "**customer_id** (identifier) ,customer_name ,city ,state ,country ,postal_code ,segment ,market ,region \n",
    "\n",
    "3. Data on vendors who supply the retailer; 65 records \n",
    "It contains fields like\n",
    "vendor ,**vendor_code** (identifier) \n",
    "\n",
    "We need to analyze the data and need to provide answer to different questions asked by company officials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95be9514",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7442207fb33a683cc6602a682d1c108",
     "grade": false,
     "grade_id": "cell-ed16b8e1f54252ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>ship_date</th>\n",
       "      <th>ship_mode</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>product_name</th>\n",
       "      <th>sales</th>\n",
       "      <th>quantity</th>\n",
       "      <th>discount</th>\n",
       "      <th>profit</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>order_priority</th>\n",
       "      <th>vendor_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MX-2014-143658</td>\n",
       "      <td>02/10/2014</td>\n",
       "      <td>06/10/2014</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SC-20575</td>\n",
       "      <td>OFF-LA-10002782</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Hon File Folder Labels, Adjustable</td>\n",
       "      <td>13.08</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.56</td>\n",
       "      <td>1.03</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>FUR-FU-10004015</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furnishings</td>\n",
       "      <td>Tenex Clock, Durable</td>\n",
       "      <td>252.16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.72</td>\n",
       "      <td>13.45</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>FUR-BO-10002352</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Ikea 3-Shelf Cabinet, Mobile</td>\n",
       "      <td>193.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.08</td>\n",
       "      <td>9.63</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>OFF-BI-10004428</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Binders</td>\n",
       "      <td>Cardinal Binder, Clear</td>\n",
       "      <td>35.44</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.96</td>\n",
       "      <td>1.37</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>OFF-AR-10004594</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Art</td>\n",
       "      <td>Sanford Canvas, Water Color</td>\n",
       "      <td>71.60</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.44</td>\n",
       "      <td>3.79</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id        order_id  order_date   ship_date       ship_mode customer_id  \\\n",
       "0       1  MX-2014-143658  02/10/2014  06/10/2014  Standard Class    SC-20575   \n",
       "1       2  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "2       3  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "3       4  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "4       5  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "\n",
       "        product_id         category sub_category  \\\n",
       "0  OFF-LA-10002782  Office Supplies       Labels   \n",
       "1  FUR-FU-10004015        Furniture  Furnishings   \n",
       "2  FUR-BO-10002352        Furniture    Bookcases   \n",
       "3  OFF-BI-10004428  Office Supplies      Binders   \n",
       "4  OFF-AR-10004594  Office Supplies          Art   \n",
       "\n",
       "                         product_name   sales  quantity  discount  profit  \\\n",
       "0  Hon File Folder Labels, Adjustable   13.08         3       0.0    4.56   \n",
       "1                Tenex Clock, Durable  252.16         8       0.0   90.72   \n",
       "2        Ikea 3-Shelf Cabinet, Mobile  193.28         2       0.0   54.08   \n",
       "3              Cardinal Binder, Clear   35.44         4       0.0    4.96   \n",
       "4         Sanford Canvas, Water Color   71.60         2       0.0   11.44   \n",
       "\n",
       "   shipping_cost order_priority vendor_code  \n",
       "0           1.03         Medium      VE_001  \n",
       "1          13.45         Medium      VE_002  \n",
       "2           9.63         Medium      VE_003  \n",
       "3           1.37         Medium      VE_004  \n",
       "4           3.79         Medium      VE_005  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "### Reading sales data\n",
    "sales = pd.read_csv('sales_data_M4.csv')\n",
    "\n",
    "### Reading customer data\n",
    "cust = pd.read_csv(r'customers.csv',encoding='iso-8859-1')\n",
    "\n",
    "### Reading vendor data\n",
    "vend = pd.read_csv(r'vendors.csv')\n",
    "\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c65629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51290, 17)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3458912c",
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "868201adf0e3beea45c39e2a4849188a",
     "grade": false,
     "grade_id": "cell-78efe7e0424ff809",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In order to solve the next questions , we need to combine all the 3 datasets into a single dataframe such that every details of sales dataframe are intact. So here we have written a data processing function.\n",
    "There are 2 tasks which are to be performed.\n",
    "1. Merge/ Join all the 3 datasets into a single dataframe such that every details of sales dataframe are intact. (Understand which should be the joining key , type of join , refer .merge() function of pandas)\n",
    "2. Convert 'order_date' into a datetime column.\n",
    "**Return output as a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b8826b2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fce96ba65cc5a5db25571a75d2347ca",
     "grade": false,
     "grade_id": "cell-760043ec960a09cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#### data_merging & order_date processing , data1 will be sales , data2 will be customer dataset & data3 will be vendor dataset.\n",
    "\n",
    "def data_process(data1,data2,data3):\n",
    "    data = data1.merge(right=data2, how=\"inner\", on=\"customer_id\")\n",
    "    data = data.merge(right=data3, how=\"inner\", on=\"vendor_code\")\n",
    "    data[\"order_date\"] = pd.to_datetime(data['order_date'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b0415e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33f7110cf96724cd31f65c6ce99f3e4c",
     "grade": false,
     "grade_id": "cell-e8c25b222f675992",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dennis\\AppData\\Local\\Temp\\ipykernel_6376\\3097288081.py:6: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  data[\"order_date\"] = pd.to_datetime(data['order_date'])\n"
     ]
    }
   ],
   "source": [
    "sales= data_process(data1=sales.copy(),data2=cust.copy(),data3=vend.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2919ff39",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a67642ea4eef0f94a4e3a46a6081afa1",
     "grade": true,
     "grade_id": "cell-24e204e9afc2c313",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sales['order_date'].dtypes=='<M8[ns]' ,'Make sure if you have converted order_date into a datetime format correctly or not.'\n",
    "assert sales.shape== (51290,26) ,'Checking size and shape of dataframe after merging is a very important check.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a443b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbdd9d97abd1fb4a8fc6b22845b5307a",
     "grade": false,
     "grade_id": "cell-7e22460af514a787",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that in this dataset we are purposefully introducing some of the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b77ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccbe7183c0629c7d646bd2a701a65e80",
     "grade": false,
     "grade_id": "cell-867679f736a58367",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.1 Return column names & missing values percentage for the columns which have % misisng value >50. Output should be a dictionary. For eg:- { column_name : %}, make sure to round off percentages to 2 decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6479b5f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "228f97ed1aabf7db12d62ccf5d29527c",
     "grade": false,
     "grade_id": "cell-eaa4ef1cb3c93902",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def missing_value_col(data):\n",
    "    \n",
    "    # Calculate the percentage of missing values for each column\n",
    "    missing_percentages = data.isnull().mean() * 100\n",
    "\n",
    "    # Filter out columns which have more than 50% missing values\n",
    "    missing_percentages = {col: round(percent, 2) for col, percent in missing_percentages.items() if percent > 50}\n",
    "\n",
    "    return missing_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bf5d86b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b039c79284e4b99a00fda192a26f4d9f",
     "grade": true,
     "grade_id": "cell-6d0d4c99764805c4",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a44b93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'postal_code': 100.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_col(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90404add",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb8633889e246a9d9cda5f41cf0770e7",
     "grade": false,
     "grade_id": "cell-00e1cff3e5f47a7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### **Senior data scientists after consulting with the business have decided that such columns needs to be dropped before going further.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab3b5c64",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "daeeadeee84f44971acd919fd87992ed",
     "grade": false,
     "grade_id": "cell-26857c8737cf80a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "high_missing_col=list(missing_value_col(data=sales).keys()) #Enter the columns with high % of missing values\n",
    "### We will drop columns with such high missing values\n",
    "sales.drop(high_missing_col,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2cf3d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(missing_value_col(data=sales).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37d3810a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_id', 'order_id', 'order_date', 'ship_date', 'ship_mode',\n",
       "       'customer_id', 'product_id', 'category', 'sub_category', 'product_name',\n",
       "       'sales', 'quantity', 'discount', 'profit', 'shipping_cost',\n",
       "       'order_priority', 'vendor_code', 'customer_name', 'city', 'state',\n",
       "       'country', 'segment', 'market', 'region', 'vendor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b50f82",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c96de899447751e3edc9661326e762bb",
     "grade": false,
     "grade_id": "cell-e795cfc2b6847586",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.2 Fill the missing data in 'category' column with appropriate method.  \n",
    "(Hint:- Remember variable 'category' & 'sub-category' are related & hierachy goes like this category -> sub-category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd2421f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7161528af2accdb5397c22ff972ec375",
     "grade": false,
     "grade_id": "cell-e10cc0483013a3f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Approach:-\n",
    "\n",
    "1. Create a key-pair dictionary where key will be product category & pair values will be sub-categories.\n",
    "\n",
    "2. Wherever category value is missing check for corresponding sub-category value. \n",
    "\n",
    "3. From sub-category value trace back its original product category value by looking in dictionary, get a product value.\n",
    "\n",
    "4. Fill the blank product category value by the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "442c7865",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5228a1362ce2d6e881abec02af1302b0",
     "grade": false,
     "grade_id": "cell-21490e58b10fdc96",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### create a dictionary where keys will be categories & sub-categories as values. store in inside Category_dict.\n",
    "\n",
    "def cat_dict(data,main_col,sub_col):    \n",
    "    \n",
    "    # Create a dictionary where keys are categories and values are lists of sub-categories\n",
    "    Category_dict = data.groupby(main_col)[sub_col].apply(list).to_dict()\n",
    "    # Remove duplicates in each list\n",
    "    Category_dict = {k: list(set(v)) for k, v in Category_dict.items()}\n",
    "    \n",
    "    return Category_dict \n",
    "\n",
    "def category_subcategory_map_dataframe(df, Category_dict, main_col, sub_col):\n",
    "    def category_subcategory_map(row):\n",
    "        if pd.isna(row[main_col]):  # If the main column is null\n",
    "            if not pd.isna(row[sub_col]):  # If the sub column is not null\n",
    "                for k, v in Category_dict.items():\n",
    "                    if row[sub_col] in Category_dict[k]:\n",
    "                        return k  # k is the correct sub-category for the category value v\n",
    "        else:\n",
    "            return row[main_col]  # If the main column is not null, return its existing value\n",
    "\n",
    "    df[main_col] = df.apply(category_subcategory_map, axis=1)\n",
    "    return df[main_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "857b5ea2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04770eb18fbe738071a15e5ed444f3cc",
     "grade": false,
     "grade_id": "cell-9da1ee987db9921e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Category_dict=cat_dict(data=sales,main_col='category',sub_col='sub_category')\n",
    "sales['category']=category_subcategory_map_dataframe(df=sales, Category_dict=Category_dict, main_col='category', sub_col='sub_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ff6172f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b67901d4b9c73d7452f398b343755b10",
     "grade": true,
     "grade_id": "cell-b7f7ba970eee54ec",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2b95a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Furniture': ['Furnishings', 'Chairs', 'Bookcases', 'Tables'],\n",
       " 'Office Supplies': ['Storage',\n",
       "  'Supplies',\n",
       "  'Appliances',\n",
       "  'Fasteners',\n",
       "  'Paper',\n",
       "  'Art',\n",
       "  'Envelopes',\n",
       "  'Labels',\n",
       "  'Binders'],\n",
       " 'Technology': ['Copiers', 'Accessories', 'Machines', 'Phones']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dict(sales,main_col=\"category\", sub_col=\"sub_category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3955f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales['category'] = category_subcategory_map_dataframe(df=sales, Category_dict=Category_dict, main_col='category', sub_col='sub_category')\n",
    "# sales[\"category\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41a848",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83ab0c15388879947cd4a98fa8b60e0a",
     "grade": false,
     "grade_id": "cell-36100bb51db5d5ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.3 ) Fill the missing values in sales column by mean. Return output series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "781b0ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246.43182388324536"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales[\"sales\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dd706e0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7877d8d6c50f31fec6f085bfa4a773e",
     "grade": false,
     "grade_id": "cell-7ef02c9d67c20af2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fill_missing(data,col):\n",
    "    # your code here\n",
    "    # Calculate the mean of the column\n",
    "    mean_val = data[col].mean()\n",
    "    \n",
    "    # Fill missing values with the mean\n",
    "    data[col] = data[col].fillna(mean_val)\n",
    "    \n",
    "    return data[col]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdde5b31",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0274ee6bba9a9b563552ac701b154a00",
     "grade": false,
     "grade_id": "cell-bd5acc23dda57e56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['sales']=fill_missing(data=sales,col='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12efde5b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "701ec470d974d5f59de71fa4e6ca140f",
     "grade": true,
     "grade_id": "cell-519682f18719b5ec",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c09d4312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['sales'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda44e9e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ddd3fbd19635ca98ff9d4e7883c4955",
     "grade": false,
     "grade_id": "cell-efe9345bbfb4eca0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.4 ) How many orders have sales falling in the following groups \n",
    "Groups :- [0,12),[12,37),[37,113),[113,186),[186,1200),[1200,max).\n",
    "\n",
    "**Note :-[a,b) indicates that bin includes a but excudes b.**\n",
    "\n",
    "**Return output series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "393b3e03",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78ec9b1d010ea1ddd4140a78214fe242",
     "grade": false,
     "grade_id": "cell-011ab56604d6dc6d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def manual_bin(data,col):\n",
    "    \n",
    "    # Define the bin edges\n",
    "    bins = [0, 12, 37, 113, 186, 1200, data[col].max()]\n",
    "    \n",
    "    # Use pandas cut function to bin the data\n",
    "    data['bins'] = pd.cut(data[col], bins, right=False)\n",
    "    \n",
    "    # Count the number of data points in each bin\n",
    "    bin_counts = data['bins'].value_counts().sort_index()\n",
    "    \n",
    "    return bin_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4af68056",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a851078ccac72dcd296bcf43bdeb4af3",
     "grade": true,
     "grade_id": "cell-c70daab6a00fb4e5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(manual_bin(data=sales,col='sales'))==pd.Series, \"Please provide output in series format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90e958cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c857082a7c2185ea47c598f49ceb51a3",
     "grade": true,
     "grade_id": "cell-5553c36ce34800ac",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ef926ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 12.0)            3708\n",
       "[12.0, 37.0)           9325\n",
       "[37.0, 113.0)         12761\n",
       "[113.0, 186.0)         5187\n",
       "[186.0, 1200.0)       18550\n",
       "[1200.0, 22638.48)     1758\n",
       "Name: bins, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_bin(sales,'sales') ### PASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ed689d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12761"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sales[(sales['sales'] >= 37.0) & (sales['sales'] < 113.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5196169",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e659cd2add50a5e6a9b26451da2da00c",
     "grade": false,
     "grade_id": "cell-411ca83596683bbc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.5 )  Sometimes, it is difficult to comprehend the sales value as a numeric value. So, the business team wants to observe the sales as Low, Medium and High categories.  Write a code to discretize the sales data and  return a series containing Low, Medium and High with the respective number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ec7bdc1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8f1c2e00fe94b07f512ff25c65c2a2d",
     "grade": false,
     "grade_id": "cell-8e4399b1bccc98dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def discrete_bin(data,col):\n",
    "    \n",
    "    # Define the bin edges based on the quantiles\n",
    "    bins = [data[col].min(), data[col].quantile(0.25), data[col].quantile(0.75), data[col].max()]\n",
    "    \n",
    "    # Define the bin labels\n",
    "    labels = ['Low', 'Medium', 'High']\n",
    "    \n",
    "    # Use pandas cut function to bin the data\n",
    "    data['bins'] = pd.cut(data[col], bins, labels=labels, include_lowest=True)\n",
    "    \n",
    "    # Count the number of data points in each bin\n",
    "    bin_counts = data['bins'].value_counts().sort_index()\n",
    "    \n",
    "    return bin_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b804fef4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd91f8895a0a23e4c820c9e703bfaf14",
     "grade": true,
     "grade_id": "cell-8f418bc782917abb",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(discrete_bin(data=sales,col='quantity'))==pd.Series, \"Please provide output in series format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d66a79ed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ac7df9091a243e222b2137186f31e5c",
     "grade": true,
     "grade_id": "cell-4a156f92f5438b15",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91a7cc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2.0, 5.0, 14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['quantity'].min(), sales['quantity'].quantile(0.25), sales['quantity'].quantile(0.75), sales['quantity'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f0f0ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    51290.000000\n",
       "mean         3.476545\n",
       "std          2.278766\n",
       "min          1.000000\n",
       "25%          2.000000\n",
       "50%          3.000000\n",
       "75%          5.000000\n",
       "max         14.000000\n",
       "Name: quantity, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['quantity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a6768d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low       21711\n",
       "Medium    20949\n",
       "High       8630\n",
       "Name: bins, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_bin(sales,'quantity')  ##PASSED 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44edcef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f2e603bd0624c8263b6e2a3068e49a5",
     "grade": false,
     "grade_id": "cell-bfaec051e6ec0804",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.6. In order to perform further analysis, we intend to utilize the 'order_priority' variable, which has categorical values ('First Class'(0) > 'Second Class'(1) > 'Standard Class'(2) > 'Same Day'(3)). To facilitate this analysis, we need to convert 'order_priority' into a numerical feature. Please encode 'order_priority' into a numerical format.Return output series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "617df49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Standard Class    29842\n",
       "Second Class       9985\n",
       "First Class        7272\n",
       "Same Day           2621\n",
       "Name: ship_mode, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales[\"ship_mode\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8f510e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales[\"order_priority\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60de4166",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5219986f75bd6abcef3d77c4657b632",
     "grade": false,
     "grade_id": "cell-d684beb2bc73d5a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Select Appropriate priority\n",
    "\n",
    "priority = {'First Class': 0, 'Second Class': 1, 'Standard Class': 2, 'Same Day': 3}\n",
    "\n",
    "\n",
    "def transforming_ordered_var(data,col,priority,nan_val):\n",
    "    \n",
    "    # Replace the categorical values with the corresponding numerical values\n",
    "    data[col] = data[col].map(priority)\n",
    "    \n",
    "    # Fill NaN values with the specified value\n",
    "    data[col].fillna(nan_val, inplace=True)\n",
    "    \n",
    "    return data[col]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de9e463f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f6fbb82e21fc0a53b8752d7dca33c52",
     "grade": false,
     "grade_id": "cell-ad8777d7794dba8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['shipping_mode_encoded']=transforming_ordered_var(data=sales,col='ship_mode',priority=priority,nan_val=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa54339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales['order_priority_encoded']=transforming_ordered_var(data=sales,col='order_priority', priority=priority,nan_val=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79b35d5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3033a0f0fa8225765187784080e18eb",
     "grade": true,
     "grade_id": "cell-f1ba60c8543b3583",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "329b7b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    29842\n",
       "1.0     9985\n",
       "0.0     7272\n",
       "3.0     2621\n",
       "5.0     1570\n",
       "Name: shipping_mode_encoded, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['shipping_mode_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebf5ea8b-e4c1-465b-8bcb-3bf3cdbe4dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    False\n",
       "Name: ship_mode, dtype: bool"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforming_ordered_var(data=sales,col='ship_mode',priority=priority,nan_val=5).value_counts().loc[lambda x:x.index==5]==1570"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b902cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales['order_priority_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b095be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96946235ba1c31c69c5900a743fca30f",
     "grade": false,
     "grade_id": "cell-b6ebfb80fba185f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.8) Outliers can be defined in different ways. For each of the following definitions of outliers, what percent of the values in the  'sales' are considered outliers? Give the answer as a percent rounded upto two decimal places.\n",
    "\n",
    "Note -\n",
    "1. 'IQR_detection' : Less than (Q1 - 1.5*IQR) and greater than (Q3 + 1.5*IQR) are considered outliers\n",
    "\n",
    "2. 'percentile_detection': Below the 3rd percentile and above the 97th percentile are considered outliers\n",
    "\n",
    "3. 'mean_SD' : Less than (mean - 3*SD) and greater than (mean + 3*SD) are considered outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bc97429",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49f6cb7c6a41b6691e798a91c98b9487",
     "grade": false,
     "grade_id": "cell-c1830537e6d495e9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def detect_outliers(data,col,method):\n",
    "    if method=='IQR_detection':\n",
    "        # Calculate the first quartile (Q1) and the third quartile (Q3)\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        \n",
    "        # Calculate the interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Determine the lower and upper bounds for outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Count the number of outliers\n",
    "        outliers = (data[col] < lower_bound) | (data[col] > upper_bound)\n",
    "    elif method=='percentile_detection':\n",
    "        # Calculate the 3rd and 97th percentiles\n",
    "        percentile_3 = data[col].quantile(0.03)\n",
    "        percentile_97 = data[col].quantile(0.97)\n",
    "        \n",
    "        # Determine the lower and upper bounds for outliers\n",
    "        lower_bound = percentile_3\n",
    "        upper_bound = percentile_97\n",
    "        \n",
    "        # Count the number of outliers\n",
    "        outliers = (data[col] < lower_bound) | (data[col] > upper_bound)\n",
    "    elif method=='mean_SD':\n",
    "        # Calculate the mean and standard deviation (SD)\n",
    "        mean = data[col].mean()\n",
    "        std_dev = data[col].std()\n",
    "        \n",
    "        # Determine the lower and upper bounds for outliers\n",
    "        lower_bound = mean - 3 * std_dev\n",
    "        upper_bound = mean + 3 * std_dev\n",
    "        \n",
    "        # Count the number of outliers\n",
    "        outliers = (data[col] < lower_bound) | (data[col] > upper_bound)\n",
    "\n",
    "    outliers_perc = float((outliers.sum() / len(data[col])) * 100)\n",
    "    \n",
    "    outliers_perc = round(outliers_perc,2)\n",
    "    \n",
    "    return outliers_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d837996",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adc1a3d9d1296b6e163ec79aae82b684",
     "grade": true,
     "grade_id": "cell-618cb2f39f3bdbb8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(detect_outliers(data\u001b[38;5;241m=\u001b[39msales,col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m,method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIQR_detection\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m==\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMake sure that output is returned as float\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "assert type(detect_outliers(data=sales,col='sales',method='IQR_detection'))==np.float, 'Make sure that output is returned as float'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e073b37d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfe0831685aec0a21f085c572cd43819",
     "grade": true,
     "grade_id": "cell-bfd2679b1e2a3929",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6706d757",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcdbc184e80602e9434ffb6ec63f615c",
     "grade": false,
     "grade_id": "cell-7e2416cf00578a58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.10) Detect upper end outliers in profit column by 'IQR_detection'. Return number of upper end outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c73a464",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efb1464ffea6ae09ca5f555613bdd556",
     "grade": false,
     "grade_id": "cell-96b2becd9fec86dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def detect_upperend_outliers(data,col):\n",
    "    \n",
    "    # Calculate the first quartile (Q1) and the third quartile (Q3)\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "        \n",
    "    # Calculate the interquartile range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "        \n",
    "    # Determine the lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "    # Count the number of outliers\n",
    "    upper_outliers = int((data[col] > upper_bound).sum())\n",
    "        \n",
    "    return upper_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2623a94f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53f5c3196b19cf7bb65c788d4fdaddb6",
     "grade": true,
     "grade_id": "cell-9623402867c6a9ef",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(detect_upperend_outliers(data=sales,col='profit'))==int , 'No of outliers should be an integer , make sure that you are returning output in integer format.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34db7408",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51f68f5109a4586e177bdb8e25237654",
     "grade": true,
     "grade_id": "cell-5e43e81906b9a713",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a455390",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "237b9c1a702099cf0ef5de527c073a4e",
     "grade": false,
     "grade_id": "cell-8439e3bd38ccbfe8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.11) Floor & Capping outliers at 97% at 3%. Return the processed column as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e198314b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2415fc7992d7cdaf6ad0b8f943766e04",
     "grade": false,
     "grade_id": "cell-f5527eddcb6c9757",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cap_and_floor_column(column, cap_percentile, floor_percentile):\n",
    "    # your code here\n",
    "    return capped_and_floored_column ## Capped ,Floored series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dfa4098f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "feca18bd11ab3ed3ecd96e098af13cd5",
     "grade": false,
     "grade_id": "cell-829558a407b31ac1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'capped_and_floored_column' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sales[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofit_outlier_capped\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcap_and_floor_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msales\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprofit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcap_percentile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m97\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloor_percentile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[48], line 3\u001b[0m, in \u001b[0;36mcap_and_floor_column\u001b[1;34m(column, cap_percentile, floor_percentile)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcap_and_floor_column\u001b[39m(column, cap_percentile, floor_percentile):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# your code here\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcapped_and_floored_column\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'capped_and_floored_column' is not defined"
     ]
    }
   ],
   "source": [
    "sales['profit_outlier_capped'] = cap_and_floor_column(column=sales['profit'], cap_percentile=97, floor_percentile=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6f1bae5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2f24af7a9c0a4f9cca886c67a1a54c0",
     "grade": true,
     "grade_id": "cell-e8e8dbefcd633180",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'profit_outlier_capped'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'profit_outlier_capped'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mround\u001b[39m(np\u001b[38;5;241m.\u001b[39mquantile(\u001b[43msales\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprofit_outlier_capped\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\u001b[38;5;241m0.97\u001b[39m),\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m301.9693\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMake sure that you are flooring and capping with correct percentiles & returning the correct output.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mround\u001b[39m(np\u001b[38;5;241m.\u001b[39mquantile(sales[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofit_outlier_capped\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;241m0.03\u001b[39m),\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m144.632\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMake sure that you are flooring and capping with correct percentiles & returning the correct output.\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'profit_outlier_capped'"
     ]
    }
   ],
   "source": [
    "assert round(np.quantile(sales['profit_outlier_capped'],0.97),4)==301.9693, 'Make sure that you are flooring and capping with correct percentiles & returning the correct output.'\n",
    "assert round(np.quantile(sales['profit_outlier_capped'],0.03),4)==-144.632, 'Make sure that you are flooring and capping with correct percentiles & returning the correct output.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04120c71",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24e3e36e708f7ad06b95792cc36bb53c",
     "grade": true,
     "grade_id": "cell-d317f90221447667",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554be141",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f871a19be79e96940943e73a7e895a99",
     "grade": false,
     "grade_id": "cell-1f2690daaff6ede8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.12) Business team is interested in knowing how many vendors have profit_outlier_capped >10000 & vendors with profit_outlier_capped <10000. Return the dataframe with 3 columns vendor  , profit_outlier_capped , profit_bins & sort it with 'profit_outlier_capped' in descending order.\n",
    "\n",
    "Instructions:-\n",
    "1. Bins should be in (a,b] format. [a,b) indicates that bin includes a but excudes b])\n",
    "2. Make sure that for 1st interval it is **left inclusive** i.e [a,b].\n",
    "3. Segment the ''profit_outlier_capped'' variable in 2 bins. (first bin with profit>10000 ,second bin with profit<10000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bde24e61",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa43f93865c896afc8c640ba73478565",
     "grade": false,
     "grade_id": "cell-77f6b02474e37c07",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (1246916953.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[52], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    # your code here\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def profit_vendor(data,col):\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01e2d1ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61d102d505d0f1a719c864515d6e3cfb",
     "grade": true,
     "grade_id": "cell-e3d429861a4da377",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'profit_vendor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[43mprofit_vendor\u001b[49m(data\u001b[38;5;241m=\u001b[39msales,col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofit_outlier_capped\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m==\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMake sure that your output is a dataframe \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m profit_vendor(data\u001b[38;5;241m=\u001b[39msales,col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofit_outlier_capped\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m==\u001b[39m(\u001b[38;5;241m65\u001b[39m,\u001b[38;5;241m3\u001b[39m) ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMake sure that shape of your dataframe is correct\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'profit_vendor' is not defined"
     ]
    }
   ],
   "source": [
    "assert type(profit_vendor(data=sales,col='profit_outlier_capped'))==pd.DataFrame ,'Make sure that your output is a dataframe '\n",
    "assert profit_vendor(data=sales,col='profit_outlier_capped').shape==(65,3) ,'Make sure that shape of your dataframe is correct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2bbb355",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89928dfd8d4f37b0488a0d03c1ee4dab",
     "grade": true,
     "grade_id": "cell-05010ee8edfc15a7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cells , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17af53a-b09a-4bfc-aa53-7f3bcfb6f581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
