{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fc60084b884af807b1eaffbd4e24c7d",
     "grade": false,
     "grade_id": "cell-f7171899571b05ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Graded Lab 5\n",
    "\n",
    "Hello ! Welcome to Graded Lab of Module 5.\n",
    "\n",
    "In the last assignment we had worked on missing values & outliers.\n",
    "Its high time when we look at the feature engineering & Principal component analysis.\n",
    "\n",
    "**So lets go ahead with the last graded assignment for the course !**\n",
    "\n",
    "In case if you are not able to recollect the problem description and data description then mentioning it below.\n",
    "\n",
    "Lets look at the problem statement,\n",
    "\n",
    "*Client: ABC Retail, Incorporated, rest-of-the-world division* \n",
    "\n",
    "***Project name: Online retail sales analysis*** \n",
    "\n",
    "An online retailer, ABC, Inc., operates in nearly 100 countries worldwide, selling furniture, office supplies and technology products to customers in three segments: consumer, corporate and home office. ABC, Inc. is a US-based company, and it has two major divisions: US and rest of the world. We are working with the rest of the world division of the company. \n",
    "\n",
    "They have provided us with online sales transaction data from 2011 to 2014.\n",
    "\n",
    "We are given 3 datasets:-\n",
    "\n",
    "1. Data on each sale; 51290 records; all data in US dollars\n",
    "It contains fields like\n",
    "**order_id** (identifier) ,order_date ,ship_date ,ship_mode ,**customer_id**(identifier) ,product_id ,category ,sub_category ,product_name ,sales ,quantity ,discount ,profit ,shipping_cost ,order_priority ,**vendor_code** (identifier) \n",
    "\n",
    "\n",
    "2. Data on the customers; 1590 records \n",
    "It contains fields like\n",
    "**customer_id** (identifier) ,customer_name ,city ,state ,country ,postal_code ,segment ,market ,region \n",
    "\n",
    "3. Data on vendors who supply the retailer; 65 records \n",
    "It contains fields like\n",
    "vendor ,**vendor_code** (identifier) \n",
    "\n",
    "We need to analyze the data and need to provide answer to different questions asked by company officials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bc1197652bf32abbd6c75aa91d59be8",
     "grade": false,
     "grade_id": "cell-4c17e0403c1c8961",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>ship_date</th>\n",
       "      <th>ship_mode</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>product_name</th>\n",
       "      <th>sales</th>\n",
       "      <th>quantity</th>\n",
       "      <th>discount</th>\n",
       "      <th>profit</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>order_priority</th>\n",
       "      <th>vendor_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MX-2014-143658</td>\n",
       "      <td>02/10/2014</td>\n",
       "      <td>06/10/2014</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SC-20575</td>\n",
       "      <td>OFF-LA-10002782</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Hon File Folder Labels, Adjustable</td>\n",
       "      <td>13.08</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.56</td>\n",
       "      <td>1.03</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>FUR-FU-10004015</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furnishings</td>\n",
       "      <td>Tenex Clock, Durable</td>\n",
       "      <td>252.16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.72</td>\n",
       "      <td>13.45</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>FUR-BO-10002352</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Ikea 3-Shelf Cabinet, Mobile</td>\n",
       "      <td>193.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.08</td>\n",
       "      <td>9.63</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>OFF-BI-10004428</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Binders</td>\n",
       "      <td>Cardinal Binder, Clear</td>\n",
       "      <td>35.44</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.96</td>\n",
       "      <td>1.37</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>OFF-AR-10004594</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Art</td>\n",
       "      <td>Sanford Canvas, Water Color</td>\n",
       "      <td>71.60</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.44</td>\n",
       "      <td>3.79</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id        order_id  order_date   ship_date       ship_mode customer_id  \\\n",
       "0       1  MX-2014-143658  02/10/2014  06/10/2014  Standard Class    SC-20575   \n",
       "1       2  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "2       3  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "3       4  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "4       5  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "\n",
       "        product_id         category sub_category  \\\n",
       "0  OFF-LA-10002782  Office Supplies       Labels   \n",
       "1  FUR-FU-10004015        Furniture  Furnishings   \n",
       "2  FUR-BO-10002352        Furniture    Bookcases   \n",
       "3  OFF-BI-10004428  Office Supplies      Binders   \n",
       "4  OFF-AR-10004594  Office Supplies          Art   \n",
       "\n",
       "                         product_name   sales  quantity  discount  profit  \\\n",
       "0  Hon File Folder Labels, Adjustable   13.08         3       0.0    4.56   \n",
       "1                Tenex Clock, Durable  252.16         8       0.0   90.72   \n",
       "2        Ikea 3-Shelf Cabinet, Mobile  193.28         2       0.0   54.08   \n",
       "3              Cardinal Binder, Clear   35.44         4       0.0    4.96   \n",
       "4         Sanford Canvas, Water Color   71.60         2       0.0   11.44   \n",
       "\n",
       "   shipping_cost order_priority vendor_code  \n",
       "0           1.03         Medium      VE_001  \n",
       "1          13.45         Medium      VE_002  \n",
       "2           9.63         Medium      VE_003  \n",
       "3           1.37         Medium      VE_004  \n",
       "4           3.79         Medium      VE_005  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "### Reading sales data\n",
    "sales = pd.read_csv('sales_data.csv')\n",
    "\n",
    "### Reading customer data\n",
    "cust = pd.read_csv(r'customers.csv',encoding='iso-8859-1')\n",
    "\n",
    "### Reading vendor data\n",
    "vend = pd.read_csv(r'vendors.csv')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00eefe9f054d05c8c11ebcfe9bc04a5b",
     "grade": false,
     "grade_id": "cell-4dc354b2761c4e3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In order to solve the next questions , we need to combine all the 3 datasets into a single dataframe such that every details of sales dataframe are intact. So here we have written a data processing function.\n",
    "There are 2 tasks which are to be performed.\n",
    "1. Merge/ Join all the 3 datasets into a single dataframe such that every details of sales dataframe are intact. (Understand which should be the joining key , type of join , refer .merge() function of pandas)\n",
    "2. Convert 'order_date' into a datetime column.\n",
    "**Return output as a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb96071fa0009e8888d15cd2e59a2839",
     "grade": false,
     "grade_id": "cell-171f8d30f5d84056",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#### data_merging & order_date processing , data1 will be sales , data2 will be customer dataset & data3 will be vendor dataset.\n",
    "\n",
    "def data_process(data1,data2,data3):\n",
    "    \n",
    "    data = data1.merge(right=data2, how=\"inner\", on=\"customer_id\")\n",
    "    data = data.merge(right=data3, how=\"inner\", on=\"vendor_code\")\n",
    "    data[\"order_date\"] = pd.to_datetime(data['order_date'], format='%d/%m/%Y')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da3c5d11eca78dbf422924bf20f58955",
     "grade": false,
     "grade_id": "cell-45cced5365115e88",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales= data_process(data1=sales.copy(),data2=cust.copy(),data3=vend.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40bc744c3c305203bf9d8b365a59b4b7",
     "grade": true,
     "grade_id": "cell-61ebe95bf598597b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sales['order_date'].dtypes=='<M8[ns]' ,'Make sure if you have converted order_date into a datetime format correctly or not.'\n",
    "assert sales.shape== (51290,26) ,'Checking size and shape of dataframe after merging is a very important check.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_id', 'order_id', 'order_date', 'ship_date', 'ship_mode',\n",
       "       'customer_id', 'product_id', 'category', 'sub_category', 'product_name',\n",
       "       'sales', 'quantity', 'discount', 'profit', 'shipping_cost',\n",
       "       'order_priority', 'vendor_code', 'customer_name', 'city', 'state',\n",
       "       'country', 'postal_code', 'segment', 'market', 'region', 'vendor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d8327a70d675ca6e91411fbd9785436",
     "grade": false,
     "grade_id": "cell-71fb2e2dc8baad31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.1) Create a feature for identifying which orders are delivered on weekends. Flag will take value 1 if order is delivered on weekends & 0 otherwise. (Sat & Sun are weekeends). Return  the output series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be1babac654c54c4ac61e7b6923eaf2e",
     "grade": false,
     "grade_id": "cell-da758c3c17ca0ef3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def weekend_flag(data):\n",
    "    \n",
    "    \"\"\"\n",
    "  Creates a feature identifying weekend orders and returns the flag series.\n",
    "\n",
    "  Args:\n",
    "    data (pd.DataFrame): The DataFrame containing the order data.\n",
    "\n",
    "  Returns:\n",
    "    pd.Series: A Series with 1 for weekend orders and 0 for others.\n",
    "    \"\"\"\n",
    "    data['weekend_orders'] = np.where(data['order_date'].dt.weekday > 4, 1, 0)  # Assign 1 for weekends, 0 otherwise\n",
    "    \n",
    "    return data['weekend_orders']  # Return the flag series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "561e9234baa3650bf2b493de38bbc08b",
     "grade": false,
     "grade_id": "cell-bb6f0475fbd0bab4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['weekend_orders']=weekend_flag(data=sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    45720\n",
       "1     5570\n",
       "Name: weekend_orders, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['weekend_orders'].value_counts()  #PASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7b3c1c7bd6dacba32dab07ea694e39d",
     "grade": true,
     "grade_id": "cell-12c0ef94c14c3ef0",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert all(sales['weekend_orders'].unique()==np.array([0, 1])) ,'Make sure that you have created flag correctly'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbffc5d6f18565d556e322491b041b57",
     "grade": false,
     "grade_id": "cell-92abb7f69b91b506",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.2) We wish to create a feature called 'discount_per_quantity'. Write a functional code to compute ratio of 2 columns. Return  the output series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a4553dfa1605ae8c0cc97c832678452",
     "grade": false,
     "grade_id": "cell-bf222819379099c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def feature_1(data,col1,col2):\n",
    "    \"\"\"\n",
    "  Computes the ratio of two columns and returns the result as a new feature series.\n",
    "\n",
    "  Args:\n",
    "    data (pd.DataFrame): The DataFrame containing the data.\n",
    "    col1 (str): Name of the first column for the ratio.\n",
    "    col2 (str): Name of the second column for the ratio.\n",
    "\n",
    "  Returns:\n",
    "    pd.Series: A Series containing the ratio of col1 to col2 for each row.\n",
    "    \"\"\"\n",
    "    data['discount_per_quantity'] = data[col1] / data[col2]  # Calculate the ratio\n",
    "    \n",
    "    return data['discount_per_quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3952efb9c9a5e72965053d005b24e6a",
     "grade": false,
     "grade_id": "cell-fdf019e6c20aa45e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['discount_per_quantity']= feature_1(data=sales,col1='discount',col2='quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    29009\n",
       "0.100000     2291\n",
       "0.050000     1656\n",
       "0.066667     1471\n",
       "0.200000     1376\n",
       "            ...  \n",
       "0.027273        1\n",
       "0.053846        1\n",
       "0.013077        1\n",
       "0.011538        1\n",
       "0.100333        1\n",
       "Name: discount_per_quantity, Length: 219, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['discount_per_quantity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0643"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sales['discount_per_quantity'].mean(),4)  #PASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eef990a45921580d13ec0179efa3491d",
     "grade": true,
     "grade_id": "cell-1d1c9c0070ebdf4e",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert round(sales['discount_per_quantity'].mean(),4)==0.0643,'Make sure that you have created feature correctly.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dbe4251dfc38440a7048e4ac4092e7a",
     "grade": false,
     "grade_id": "cell-04ae737147acedb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.3) Create a feature for finding cumulative sales for every customer. Return  the output series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69e435bdc1ceddfdb8f8c7fd5b067e6d",
     "grade": false,
     "grade_id": "cell-23b8a0fddaa72e30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cumulative_sales(data):\n",
    "    \n",
    "    \"\"\"\n",
    "  Creates a feature for cumulative sales for each customer and returns the series.\n",
    "\n",
    "  Args:\n",
    "    data (pd.DataFrame): The DataFrame containing sales data with a 'customer_id' column.\n",
    "\n",
    "  Returns:\n",
    "    pd.Series: A Series containing cumulative sales for each customer.\n",
    "    \"\"\"\n",
    "    \n",
    "    data['cumulative_sales'] = data.groupby('customer_id')['sales'].transform(pd.Series.cumsum)  # Calculate cumulative sales\n",
    "    \n",
    "    return data['cumulative_sales']  # Return the new feature series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19dbda090f1c9bba93f2fef835d405d8",
     "grade": false,
     "grade_id": "cell-ce218cadc5b9b7b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Sorting the dataframe wrto customer_id & order_date\n",
    "sales.sort_values(['customer_id','order_date'],ascending=[1,1],inplace=True)\n",
    "### Applying cumulative_sales function\n",
    "sales['cumulative_sales']=cumulative_sales(data=sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29198     673.5680\n",
       "29199     726.5480\n",
       "8548      778.2590\n",
       "8549      823.1885\n",
       "8550     1102.0385\n",
       "           ...    \n",
       "46464    8100.9629\n",
       "47330    8546.2889\n",
       "16678    8762.2889\n",
       "18475    9350.3114\n",
       "49055    9479.3444\n",
       "Name: cumulative_sales, Length: 51290, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['cumulative_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e06c34e321f5e2e4f28e0be7918ece13",
     "grade": true,
     "grade_id": "cell-f88f29cf32252ab7",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert round(sales[sales['customer_id']=='ZC-21910']['cumulative_sales'].max(),2)==28472.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28472.82"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sales[sales['customer_id']=='ZC-21910']['cumulative_sales'].max(),2) #PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a94db7331869b4a5c20455202bf6da4",
     "grade": false,
     "grade_id": "cell-edca82aa344fa2ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.4) Please demonstrate how to enhance a given dataset by introducing a new feature that records the frequency of same-day purchases made by each customer. The desired outcome should be a modified dataframe containing a variable named 'same_day_purchase_frequency' which accurately portrays the same-day purchase behavior of individual customers.\n",
    "#### same_day_purchase_frequency will be the frequency of the orders made on same day. If customer 'ABC' has placed 2 orders on 2nd Jan 23 then 'same_day_purchase_frequency'for this customer for 2nd Jan 23 will be 2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TROUBLESHOOTING FUNCTION\n",
    "\n",
    "# def same_day_purchase(data):\n",
    "    \n",
    "#     # Group by 'customer_id' and date, and count the orders, store count of orders in variable named 'order_count'\n",
    "#     order_counts = data.groupby(['customer_id', 'order_date'])['order_id'].count()  # Assuming 'order_id' is unique per order\n",
    "    \n",
    "#     # Filter for same-day purchases (order_count > 1)\n",
    "#     same_day_purchases = order_counts[order_counts > 1]\n",
    "    \n",
    "#     # Group by 'customer_id' and calculate the same-day purchase frequency , name that column as 'same_day_purchase_frequency'\n",
    "#     same_day_purchase_frequency = same_day_purchases.groupby('customer_id').size().rename('same_day_purchase_frequency')\n",
    "    \n",
    "#     # Merge the result with the original DataFrame to add the same-day purchase frequency as a new column  \n",
    "#     data = data.merge(same_day_purchase_frequency.to_frame().reset_index(), on='customer_id', how='left')\n",
    "    \n",
    "#     # Fill missing values with 0 (for customers with no same-day purchases)\n",
    "#     data['same_day_purchase_frequency'].fillna(0, inplace=True)\n",
    "    \n",
    "#     return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same_day_purchase(sales.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same_day_purchase(sales.copy()).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdb2743d81b7f441c77e26e51ba40bac",
     "grade": false,
     "grade_id": "cell-11502c58370a30cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def same_day_purchase(data):\n",
    "    \n",
    "    # Group by 'customer_id' and date, and count the orders, store count of orders in variable named 'order_count'\n",
    "    order_counts = data.groupby(['customer_id', 'order_date'])['order_id'].count()  # Assuming 'order_id' is unique per order\n",
    "    \n",
    "    # Filter for same-day purchases (order_count > 1)\n",
    "    same_day_purchases = order_counts[order_counts > 1]\n",
    "    \n",
    "    # Group by 'customer_id' and calculate the same-day purchase frequency , name that column as 'same_day_purchase_frequency'\n",
    "    same_day_purchase_frequency = same_day_purchases.groupby('customer_id').size().rename('same_day_purchase_frequency')\n",
    "    \n",
    "    # Merge the result with the original DataFrame to add the same-day purchase frequency as a new column  \n",
    "    data = data.merge(same_day_purchase_frequency.to_frame().reset_index(), on='customer_id', how='left')\n",
    "    \n",
    "    # Fill missing values with 0 (for customers with no same-day purchases)\n",
    "    data['same_day_purchase_frequency'].fillna(0, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9485edecbbb7cf8550559814732b784",
     "grade": true,
     "grade_id": "cell-1a74a24a4da6dd2d",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales_new=same_day_purchase(data=sales.copy())\n",
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert float(sales_new[sales_new['customer_id']=='ZC-11910']['same_day_purchase_frequency'].unique())==0,'Make sure that you have created variable correctly.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>ship_date</th>\n",
       "      <th>ship_mode</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>product_name</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>segment</th>\n",
       "      <th>market</th>\n",
       "      <th>region</th>\n",
       "      <th>vendor</th>\n",
       "      <th>weekend_orders</th>\n",
       "      <th>discount_per_quantity</th>\n",
       "      <th>cumulative_sales</th>\n",
       "      <th>same_day_purchase_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33526</td>\n",
       "      <td>CA-2011-128055</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>05/04/2011</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>AA-10315</td>\n",
       "      <td>OFF-BI-10004390</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Binders</td>\n",
       "      <td>GBC DocuBind 200 Manual Binding Machine</td>\n",
       "      <td>...</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>LATAM</td>\n",
       "      <td>LATAM-North</td>\n",
       "      <td>Lifoods</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>673.5680</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33527</td>\n",
       "      <td>CA-2011-128055</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>05/04/2011</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>AA-10315</td>\n",
       "      <td>OFF-AP-10002765</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Fellowes Advanced Computer Series Surge Protec...</td>\n",
       "      <td>...</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>LATAM</td>\n",
       "      <td>LATAM-North</td>\n",
       "      <td>Lifoods</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>726.5480</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27384</td>\n",
       "      <td>ID-2011-40953</td>\n",
       "      <td>2011-07-04</td>\n",
       "      <td>07/07/2011</td>\n",
       "      <td>First Class</td>\n",
       "      <td>AA-10315</td>\n",
       "      <td>OFF-SU-10003723</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>Elite Shears, High Speed</td>\n",
       "      <td>...</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>LATAM</td>\n",
       "      <td>LATAM-North</td>\n",
       "      <td>Low Tide Corp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>778.2590</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27385</td>\n",
       "      <td>ID-2011-40953</td>\n",
       "      <td>2011-07-04</td>\n",
       "      <td>07/07/2011</td>\n",
       "      <td>First Class</td>\n",
       "      <td>AA-10315</td>\n",
       "      <td>OFF-LA-10000425</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Avery Shipping Labels, Alphabetical</td>\n",
       "      <td>...</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>LATAM</td>\n",
       "      <td>LATAM-North</td>\n",
       "      <td>Low Tide Corp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>823.1885</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27387</td>\n",
       "      <td>ID-2011-40953</td>\n",
       "      <td>2011-07-04</td>\n",
       "      <td>07/07/2011</td>\n",
       "      <td>First Class</td>\n",
       "      <td>AA-10315</td>\n",
       "      <td>OFF-SU-10001308</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>Fiskars Trimmer, Serrated</td>\n",
       "      <td>...</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>LATAM</td>\n",
       "      <td>LATAM-North</td>\n",
       "      <td>Low Tide Corp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034615</td>\n",
       "      <td>1102.0385</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id        order_id order_date   ship_date       ship_mode customer_id  \\\n",
       "0   33526  CA-2011-128055 2011-03-31  05/04/2011  Standard Class    AA-10315   \n",
       "1   33527  CA-2011-128055 2011-03-31  05/04/2011  Standard Class    AA-10315   \n",
       "2   27384   ID-2011-40953 2011-07-04  07/07/2011     First Class    AA-10315   \n",
       "3   27385   ID-2011-40953 2011-07-04  07/07/2011     First Class    AA-10315   \n",
       "4   27387   ID-2011-40953 2011-07-04  07/07/2011     First Class    AA-10315   \n",
       "\n",
       "        product_id         category sub_category  \\\n",
       "0  OFF-BI-10004390  Office Supplies      Binders   \n",
       "1  OFF-AP-10002765  Office Supplies   Appliances   \n",
       "2  OFF-SU-10003723  Office Supplies     Supplies   \n",
       "3  OFF-LA-10000425  Office Supplies       Labels   \n",
       "4  OFF-SU-10001308  Office Supplies     Supplies   \n",
       "\n",
       "                                        product_name  ...  country  \\\n",
       "0            GBC DocuBind 200 Manual Binding Machine  ...   Mexico   \n",
       "1  Fellowes Advanced Computer Series Surge Protec...  ...   Mexico   \n",
       "2                           Elite Shears, High Speed  ...   Mexico   \n",
       "3                Avery Shipping Labels, Alphabetical  ...   Mexico   \n",
       "4                          Fiskars Trimmer, Serrated  ...   Mexico   \n",
       "\n",
       "   postal_code   segment  market       region         vendor weekend_orders  \\\n",
       "0          NaN  Consumer   LATAM  LATAM-North        Lifoods              0   \n",
       "1          NaN  Consumer   LATAM  LATAM-North        Lifoods              0   \n",
       "2          NaN  Consumer   LATAM  LATAM-North  Low Tide Corp              0   \n",
       "3          NaN  Consumer   LATAM  LATAM-North  Low Tide Corp              0   \n",
       "4          NaN  Consumer   LATAM  LATAM-North  Low Tide Corp              0   \n",
       "\n",
       "  discount_per_quantity cumulative_sales same_day_purchase_frequency  \n",
       "0              0.100000         673.5680                        10.0  \n",
       "1              0.000000         726.5480                        10.0  \n",
       "2              0.225000         778.2590                        10.0  \n",
       "3              0.064286         823.1885                        10.0  \n",
       "4              0.034615        1102.0385                        10.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_new = same_day_purchase(data=sales.copy())\n",
    "sales_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(sales_new[sales_new['customer_id']=='ZC-11910']['same_day_purchase_frequency'].unique()) #PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3413d31173bc31ae53578a4f1b2fa14b",
     "grade": false,
     "grade_id": "cell-7bdd8d0b6ca47c10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.5) Create a variable which will calculate weighted sales per market. Return  the output series.\n",
    "Weights for every region are :-'LATAM':1, 'EMEA':1.3, 'Africa':2.7, 'Canada':1.4, 'EU':2.8, 'APAC':3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LATAM     41265\n",
       "EMEA       4884\n",
       "Africa     4798\n",
       "Canada      313\n",
       "EU           23\n",
       "APAC          7\n",
       "Name: market, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.market.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20c298d50c1a843850662da6f77a0f4f",
     "grade": false,
     "grade_id": "cell-47084e349b64bd0d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def weighted_sales(data):\n",
    "    # Write a lambda function & apply it to dataframe.Kindly ignore raiseNotImplementError\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates weighted sales per market and returns the output series.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The DataFrame containing sales data with 'market' and 'sales' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Series containing weighted sales for each market.\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = {'LATAM': 1, 'EMEA': 1.3, 'Africa': 2.7, 'Canada': 1.4, 'EU': 2.8, 'APAC': 3.5}\n",
    "    \n",
    "    # Define a lambda function to calculate weighted sales\n",
    "    calculate_weighted_sales = lambda row: row['sales'] * weights[row['market']]\n",
    "    \n",
    "    # Apply the lambda function to the DataFrame to create the new feature\n",
    "    data['weighted_market_sales'] = data.apply(calculate_weighted_sales, axis=1)\n",
    "    \n",
    "    return data['weighted_market_sales']  # Return the new feature series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f027b99d898df5ff494ef6222aa01040",
     "grade": false,
     "grade_id": "cell-e9fad939365ebe57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['weighted_market_sales']=weighted_sales(data=sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29198    673.5680\n",
       "29199     52.9800\n",
       "8548      51.7110\n",
       "8549      44.9295\n",
       "8550     278.8500\n",
       "Name: weighted_market_sales, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['weighted_market_sales'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82d66c7c73edac8f37f383cbfc68fafc",
     "grade": true,
     "grade_id": "cell-389d62fab17c8c2f",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert round(float(sales[(sales['market']=='Africa') & (round(sales['sales'],4)==58.83)]['weighted_market_sales'].unique()),2)==158.84, 'Make sure that ypu have created column correctly.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158.84"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(sales[(sales['market']=='Africa') & (round(sales['sales'],4)==58.83)]['weighted_market_sales'].unique()),2)#PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9afa77f2faa0eb29cbeb7b2c0dd9381d",
     "grade": false,
     "grade_id": "cell-257ca79e2212fc23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Most of the variables in our data are categorical in nature & for further anlysis purpose if we convert them by ordinal encoding or one hot encoding, we will be left with too many variables.\n",
    "If we have too many variables in the data , it might cause trouble in later stages like machine learning model building.\n",
    "1. Having too many variables can lead to overfitting and poor generalization to new data.\n",
    "2. It can make it difficult to analyze and interpret the data and identify the most important variables.\n",
    "3. It can increase computational complexity and time required to build and train a model.\n",
    "\n",
    "How to deal with this ?\n",
    "\n",
    "Wait , we have learned about **Principal component analysis** , we can leverage that method here for **dimensionality reduction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63302da6ba845b2859f2cee3e5198f4d",
     "grade": false,
     "grade_id": "cell-532602ee41242bbd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.6 ) Complete the following code for PCA implementation. Return the no of PC's required for capturing the 80% of variation, variance explained by the PC's ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_id', 'order_id', 'order_date', 'ship_date', 'ship_mode',\n",
       "       'customer_id', 'product_id', 'category', 'sub_category', 'product_name',\n",
       "       'sales', 'quantity', 'discount', 'profit', 'shipping_cost',\n",
       "       'order_priority', 'vendor_code', 'customer_name', 'city', 'state',\n",
       "       'country', 'postal_code', 'segment', 'market', 'region', 'vendor',\n",
       "       'weekend_orders', 'discount_per_quantity', 'cumulative_sales',\n",
       "       'weighted_market_sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales[\"sub_category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TROUBLESHOOT FUNCTION\n",
    "\n",
    "# def PCA(data,target=0.80):\n",
    "    \n",
    "    \n",
    "#     # Treating ordinal variable ,\n",
    "#     # order_priority : 'Medium':2, 'Low':1, 'High':3, 'Critical':4 \n",
    "#     data['order_priority_encoded'] = data['order_priority'].map({'Medium': 2, 'Low': 1, 'High': 3, 'Critical': 4})\n",
    "    \n",
    "#     # Treating missing values\n",
    "#     # Impute the missing values in 'order_priority_encoded','ship_mode' by mode, \n",
    "#     data['order_priority_encoded'].fillna(data['order_priority_encoded'].mode()[0], inplace=True)\n",
    "#     data['ship_mode'].fillna(data['ship_mode'].mode()[0], inplace=True)\n",
    "    \n",
    "#     # Treating Nominal variables ,'ship_mode','category','sub_category' \n",
    "#     # (while encoding them make sure to select k-1 dummy variables for a variable with k categories)\n",
    "#     data = pd.get_dummies(data, columns=['ship_mode', 'category', 'sub_category'], drop_first=True)\n",
    "    \n",
    "#     # Final data selection\n",
    "#     # Select all the variables with 'sales','quantity','discount','profit','shipping_cost',\n",
    "#     # order_priority_encoded' & dummies in 'ship_mode','category','sub_category'.\n",
    "    \n",
    "#     data_1 = data[['sales','quantity','discount','profit','shipping_cost','order_priority_encoded',\n",
    "#                    'ship_mode_Same Day','ship_mode_Second Class','ship_mode_Standard Class',\n",
    "#                    'category_Office Supplies','category_Technology','sub_category_Appliances',\n",
    "#                    'sub_category_Art','sub_category_Binders','sub_category_Bookcases','sub_category_Chairs',\n",
    "#                    'sub_category_Copiers','sub_category_Envelopes','sub_category_Fasteners',\n",
    "#                    'sub_category_Furnishings','sub_category_Labels','sub_category_Machines',\n",
    "#                    'sub_category_Paper','sub_category_Phones','sub_category_Storage',\n",
    "#                    'sub_category_Supplies','sub_category_Tables']]\n",
    "    \n",
    "#     # Standardize the data\n",
    "#     sc = StandardScaler()\n",
    "    \n",
    "#     cols = ['sales','quantity','discount','profit','shipping_cost','order_priority_encoded']\n",
    "    \n",
    "#     for col in cols:\n",
    "#         data_1[col] = sc.fit_transform(data_1[[col]])\n",
    "        \n",
    "#     from sklearn.decomposition import PCA\n",
    "    \n",
    "#     # Create a PCA instance    \n",
    "#     pca = PCA()\n",
    "    \n",
    "#     # Fit PCA to the scaled data\n",
    "#     pca.fit(data_1) # Write your code in place of None\n",
    "    \n",
    "#     # Calculate cumulative explained variance\n",
    "#     explained_variance_ratio = pca.explained_variance_ratio_\n",
    "#     cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "#     target_variation = target\n",
    "#     n_components = np.argmax(cumulative_variance >= target_variation) + 1\n",
    "    \n",
    "#     # Excellent we got no of pcs which are required for capturing the target variation in the data\n",
    "    \n",
    "#     ### Fitting PCA again with no of pc's we got above.\n",
    "#     pca = PCA(n_components=n_components)\n",
    "    \n",
    "#     # Fit PCA to the scaled data\n",
    "#     pca.fit(data_1)\n",
    "    \n",
    "#     #  Calculate cumulative explained variance\n",
    "#     explained_variance_ratio = pca.explained_variance_ratio_\n",
    "       \n",
    "#     return n_components,explained_variance_ratio    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA(sales.copy(), target=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73f56d08b62547c5a91e2fa94ccef16b",
     "grade": false,
     "grade_id": "cell-033f0d1768c98329",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def PCA(data,target=0.80):\n",
    "    \n",
    "    \n",
    "    # Treating ordinal variable ,\n",
    "    # order_priority : 'Medium':2, 'Low':1, 'High':3, 'Critical':4 \n",
    "    data['order_priority_encoded'] = data['order_priority'].map({'Medium': 2, 'Low': 1, 'High': 3, 'Critical': 4})\n",
    "    \n",
    "    # Treating missing values\n",
    "    # Impute the missing values in 'order_priority_encoded','ship_mode' by mode, \n",
    "    data['order_priority_encoded'].fillna(data['order_priority_encoded'].mode()[0], inplace=True)\n",
    "    data['ship_mode'].fillna(data['ship_mode'].mode()[0], inplace=True)\n",
    "    \n",
    "    # Treating Nominal variables ,'ship_mode','category','sub_category' \n",
    "    # (while encoding them make sure to select k-1 dummy variables for a variable with k categories)\n",
    "    data = pd.get_dummies(data, columns=['ship_mode', 'category', 'sub_category'], drop_first=True)\n",
    "    \n",
    "    # Final data selection\n",
    "    # Select all the variables with 'sales','quantity','discount','profit','shipping_cost',\n",
    "    # order_priority_encoded' & dummies in 'ship_mode','category','sub_category'.\n",
    "    \n",
    "    data_1 = data[['sales','quantity','discount','profit','shipping_cost','order_priority_encoded',\n",
    "                   'ship_mode_Same Day','ship_mode_Second Class','ship_mode_Standard Class',\n",
    "                   'category_Office Supplies','category_Technology','sub_category_Appliances',\n",
    "                   'sub_category_Art','sub_category_Binders','sub_category_Bookcases','sub_category_Chairs',\n",
    "                   'sub_category_Copiers','sub_category_Envelopes','sub_category_Fasteners',\n",
    "                   'sub_category_Furnishings','sub_category_Labels','sub_category_Machines',\n",
    "                   'sub_category_Paper','sub_category_Phones','sub_category_Storage',\n",
    "                   'sub_category_Supplies','sub_category_Tables']]\n",
    "    \n",
    "    # Standardize the data\n",
    "    sc = StandardScaler()\n",
    "    \n",
    "    cols = ['sales','quantity','discount','profit','shipping_cost','order_priority_encoded']\n",
    "    \n",
    "    for col in cols:\n",
    "        data_1[col] = sc.fit_transform(data_1[[col]])\n",
    "        \n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    # Create a PCA instance    \n",
    "    pca = PCA()\n",
    "    \n",
    "    # Fit PCA to the scaled data\n",
    "    pca.fit(data_1) # Write your code in place of None\n",
    "    \n",
    "    # Calculate cumulative explained variance\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "    target_variation = target\n",
    "    n_components = np.argmax(cumulative_variance >= target_variation) + 1\n",
    "    \n",
    "    # Excellent we got no of pcs which are required for capturing the target variation in the data\n",
    "    \n",
    "    ### Fitting PCA again with no of pc's we got above.\n",
    "    pca = PCA(n_components=n_components)\n",
    "    \n",
    "    # Fit PCA to the scaled data\n",
    "    pca.fit(data_1)\n",
    "    \n",
    "    #  Calculate cumulative explained variance\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "       \n",
    "    return n_components,explained_variance_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1283ef2455ee18599ddbfc61cf61a6aa",
     "grade": true,
     "grade_id": "cell-095ce6ebc95af61e",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert type(PCA(data=sales.copy())[0])==np.int64 , 'Number of components required for capturing target variation should be in integer format.'\n",
    "assert type(PCA(data=sales.copy())[1])==np.ndarray , 'Type of variation captured should be in an array format.'\n",
    "assert [round(x,4) for x in list(PCA(data=sales.copy())[1])][0]==0.3012, 'Make sure that you are returning correct values for output.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA(data=sales.copy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(PCA(data=sales.copy())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30122233, 0.14869927, 0.1394773 , 0.1093968 , 0.07239173,\n",
       "       0.04129315])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA(data=sales.copy())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(PCA(data=sales.copy())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30122233079178184"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(PCA(data=sales.copy())[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3012"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[round(x,4) for x in list(PCA(data=sales.copy())[1])][0]  #PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd0b9a4d237bfddb01c0f7ed304c5e7d",
     "grade": false,
     "grade_id": "cell-99f83690c838e50a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.7) How much variation was explained by 3rd principal component ? \n",
    "**Round output rounded upto 4 digits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b1d6d3561148f2fb0ea58db6f853f08",
     "grade": false,
     "grade_id": "cell-d668bca10bcf9149",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def var_expl(variation_explained):\n",
    "       \n",
    "    \"\"\"\n",
    "    Extracts and rounds the explained variance of the 3rd principal component.\n",
    "\n",
    "    Args:\n",
    "        variation_explained (list or array): A list or array containing the explained variance of each principal component.\n",
    "\n",
    "    Returns:\n",
    "        float: The explained variance of the 3rd principal component, rounded to 4 decimal places.\n",
    "    \"\"\"\n",
    "\n",
    "    third_pc_variance = variation_explained[2]  # Access the 3rd PC's explained variance (index 2)\n",
    "    rounded_variance = round(third_pc_variance, 4)  # Round to 4 decimal places\n",
    "    \n",
    "    return rounded_variance\n",
    "    #PASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2b2d2a933ca3017b59536de505adc48",
     "grade": true,
     "grade_id": "cell-cf2fbc4c16e8ba3d",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
