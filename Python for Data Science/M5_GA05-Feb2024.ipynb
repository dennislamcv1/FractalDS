{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fc60084b884af807b1eaffbd4e24c7d",
     "grade": false,
     "grade_id": "cell-f7171899571b05ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Graded Lab 5\n",
    "\n",
    "Hello ! Welcome to Graded Lab of Module 5.\n",
    "\n",
    "In the last assignment we had worked on missing values & outliers.\n",
    "Its high time when we look at the feature engineering & Principal component analysis.\n",
    "\n",
    "**So lets go ahead with the last graded assignment for the course !**\n",
    "\n",
    "In case if you are not able to recollect the problem description and data description then mentioning it below.\n",
    "\n",
    "Lets look at the problem statement,\n",
    "\n",
    "*Client: ABC Retail, Incorporated, rest-of-the-world division* \n",
    "\n",
    "***Project name: Online retail sales analysis*** \n",
    "\n",
    "An online retailer, ABC, Inc., operates in nearly 100 countries worldwide, selling furniture, office supplies and technology products to customers in three segments: consumer, corporate and home office. ABC, Inc. is a US-based company, and it has two major divisions: US and rest of the world. We are working with the rest of the world division of the company. \n",
    "\n",
    "They have provided us with online sales transaction data from 2011 to 2014.\n",
    "\n",
    "We are given 3 datasets:-\n",
    "\n",
    "1. Data on each sale; 51290 records; all data in US dollars\n",
    "It contains fields like\n",
    "**order_id** (identifier) ,order_date ,ship_date ,ship_mode ,**customer_id**(identifier) ,product_id ,category ,sub_category ,product_name ,sales ,quantity ,discount ,profit ,shipping_cost ,order_priority ,**vendor_code** (identifier) \n",
    "\n",
    "\n",
    "2. Data on the customers; 1590 records \n",
    "It contains fields like\n",
    "**customer_id** (identifier) ,customer_name ,city ,state ,country ,postal_code ,segment ,market ,region \n",
    "\n",
    "3. Data on vendors who supply the retailer; 65 records \n",
    "It contains fields like\n",
    "vendor ,**vendor_code** (identifier) \n",
    "\n",
    "We need to analyze the data and need to provide answer to different questions asked by company officials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor update: Jan 29, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bc1197652bf32abbd6c75aa91d59be8",
     "grade": false,
     "grade_id": "cell-4c17e0403c1c8961",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>ship_date</th>\n",
       "      <th>ship_mode</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>product_name</th>\n",
       "      <th>sales</th>\n",
       "      <th>quantity</th>\n",
       "      <th>discount</th>\n",
       "      <th>profit</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>order_priority</th>\n",
       "      <th>vendor_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MX-2014-143658</td>\n",
       "      <td>02/10/2014</td>\n",
       "      <td>06/10/2014</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SC-20575</td>\n",
       "      <td>OFF-LA-10002782</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Hon File Folder Labels, Adjustable</td>\n",
       "      <td>13.08</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.56</td>\n",
       "      <td>1.03</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>FUR-FU-10004015</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furnishings</td>\n",
       "      <td>Tenex Clock, Durable</td>\n",
       "      <td>252.16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.72</td>\n",
       "      <td>13.45</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>FUR-BO-10002352</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Ikea 3-Shelf Cabinet, Mobile</td>\n",
       "      <td>193.28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.08</td>\n",
       "      <td>9.63</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>OFF-BI-10004428</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Binders</td>\n",
       "      <td>Cardinal Binder, Clear</td>\n",
       "      <td>35.44</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.96</td>\n",
       "      <td>1.37</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MX-2012-155047</td>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>20/10/2012</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KW-16570</td>\n",
       "      <td>OFF-AR-10004594</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Art</td>\n",
       "      <td>Sanford Canvas, Water Color</td>\n",
       "      <td>71.60</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.44</td>\n",
       "      <td>3.79</td>\n",
       "      <td>Medium</td>\n",
       "      <td>VE_005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id        order_id  order_date   ship_date       ship_mode customer_id  \\\n",
       "0       1  MX-2014-143658  02/10/2014  06/10/2014  Standard Class    SC-20575   \n",
       "1       2  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "2       3  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "3       4  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "4       5  MX-2012-155047  15/10/2012  20/10/2012  Standard Class    KW-16570   \n",
       "\n",
       "        product_id         category sub_category  \\\n",
       "0  OFF-LA-10002782  Office Supplies       Labels   \n",
       "1  FUR-FU-10004015        Furniture  Furnishings   \n",
       "2  FUR-BO-10002352        Furniture    Bookcases   \n",
       "3  OFF-BI-10004428  Office Supplies      Binders   \n",
       "4  OFF-AR-10004594  Office Supplies          Art   \n",
       "\n",
       "                         product_name   sales  quantity  discount  profit  \\\n",
       "0  Hon File Folder Labels, Adjustable   13.08         3       0.0    4.56   \n",
       "1                Tenex Clock, Durable  252.16         8       0.0   90.72   \n",
       "2        Ikea 3-Shelf Cabinet, Mobile  193.28         2       0.0   54.08   \n",
       "3              Cardinal Binder, Clear   35.44         4       0.0    4.96   \n",
       "4         Sanford Canvas, Water Color   71.60         2       0.0   11.44   \n",
       "\n",
       "   shipping_cost order_priority vendor_code  \n",
       "0           1.03         Medium      VE_001  \n",
       "1          13.45         Medium      VE_002  \n",
       "2           9.63         Medium      VE_003  \n",
       "3           1.37         Medium      VE_004  \n",
       "4           3.79         Medium      VE_005  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "### Reading sales data\n",
    "sales = pd.read_csv('sales_data.csv')\n",
    "\n",
    "### Reading customer data\n",
    "cust = pd.read_csv(r'customers.csv',encoding='iso-8859-1')\n",
    "\n",
    "### Reading vendor data\n",
    "vend = pd.read_csv(r'vendors.csv')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00eefe9f054d05c8c11ebcfe9bc04a5b",
     "grade": false,
     "grade_id": "cell-4dc354b2761c4e3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In order to solve the next questions , we need to combine all the 3 datasets into a single dataframe such that every details of sales dataframe are intact. So here we have written a data processing function.\n",
    "There are 2 tasks which are to be performed.\n",
    "1. Merge/ Join all the 3 datasets into a single dataframe such that every details of sales dataframe are intact. (Understand which should be the joining key , type of join , refer .merge() function of pandas)\n",
    "2. Convert 'order_date' into a datetime column.\n",
    "**Return output as a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data_merging & order_date processing , data1 will be sales , data2 will be customer dataset & data3 will be vendor dataset.\n",
    "\n",
    "# def data_process(data1,data2,data3):\n",
    "    \n",
    "#     data = data1.merge(right=data2, how=\"inner\", on=\"customer_id\")\n",
    "#     data = data.merge(right=data3, how=\"inner\", on=\"vendor_code\")\n",
    "#     data[\"order_date\"] = pd.to_datetime(data['order_date'])\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb96071fa0009e8888d15cd2e59a2839",
     "grade": false,
     "grade_id": "cell-171f8d30f5d84056",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#### data_merging & order_date processing , data1 will be sales , data2 will be customer dataset & data3 will be vendor dataset.\n",
    "\n",
    "def data_process(data1,data2,data3):\n",
    "    \n",
    "    # Merge data1 and data2 on 'customer_id'\n",
    "\n",
    "    data = pd.merge(data1, data2, on='customer_id', how='left')\n",
    "\n",
    "    # Merge the result with data3 on 'vendor_code'\n",
    "\n",
    "    data = pd.merge(data, data3, on='vendor_code', how='left')\n",
    "\n",
    "    # Convert 'order_date' into a datetime column\n",
    "\n",
    "    data['order_date'] = pd.to_datetime(data['order_date'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da3c5d11eca78dbf422924bf20f58955",
     "grade": false,
     "grade_id": "cell-45cced5365115e88",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales= data_process(data1=sales.copy(),data2=cust.copy(),data3=vend.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40bc744c3c305203bf9d8b365a59b4b7",
     "grade": true,
     "grade_id": "cell-61ebe95bf598597b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sales['order_date'].dtypes=='<M8[ns]' ,'Make sure if you have converted order_date into a datetime format correctly or not.'\n",
    "assert sales.shape== (51290,26) ,'Checking size and shape of dataframe after merging is a very important check.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['order_date'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51290, 26)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be2d14217e8998c2e6cdc3d0ba26c154",
     "grade": false,
     "grade_id": "cell-71fb2e2dc8baad31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.1) Create a feature for identifying which orders are ordered on weekends. Flag will take value 1 if order is ordered on weekends & 0 otherwise. (Sat & Sun are weekends). Return  the output series.\n",
    "\n",
    "Hint: Think of using weekday() function, consider'order_date' as the required columns for computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be1babac654c54c4ac61e7b6923eaf2e",
     "grade": false,
     "grade_id": "cell-da758c3c17ca0ef3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# def weekend_flag(data):\n",
    "       \n",
    "#     data['weekend_orders'] = np.where(data['order_date'].dt.weekday > 4, 1, 0)  # Assign 1 for weekends, 0 otherwise\n",
    "    \n",
    "#     return data['weekend_orders']  # Return the flag series    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekend_flag(data):\n",
    "    \n",
    "  \n",
    "    # dt.dayoftheweek >= 5  # 5 and 6 represent Saturday and Sunday\n",
    "    \n",
    "    data['dayweek'] = data['order_date'].dt.dayofweek\n",
    "\n",
    "    # Create a new column 'delivered_on_weekend' with 1 for weekend deliveries and 0 for others\n",
    "    data['delivered_on_weekend'] = (data['dayweek'].apply(lambda x:1 if x >=5 else 0)).astype(int)\n",
    "    \n",
    "    return data['delivered_on_weekend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "561e9234baa3650bf2b493de38bbc08b",
     "grade": false,
     "grade_id": "cell-bb6f0475fbd0bab4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['weekend_orders']=weekend_flag(data=sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7b3c1c7bd6dacba32dab07ea694e39d",
     "grade": true,
     "grade_id": "cell-12c0ef94c14c3ef0",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert all(sales['weekend_orders'].unique()==np.array([0, 1])) ,'Make sure that you have created flag correctly'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "51285    0\n",
       "51286    0\n",
       "51287    0\n",
       "51288    0\n",
       "51289    0\n",
       "Name: weekend_orders, Length: 51290, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['weekend_orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    42288\n",
       "1     9002\n",
       "Name: weekend_orders, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['weekend_orders'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['weekend_orders'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbffc5d6f18565d556e322491b041b57",
     "grade": false,
     "grade_id": "cell-92abb7f69b91b506",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.2) We wish to create a feature called 'discount_per_quantity'. Write a functional code to compute ratio of 2 columns. Return  the output series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a4553dfa1605ae8c0cc97c832678452",
     "grade": false,
     "grade_id": "cell-bf222819379099c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def feature_1(data,col1,col2):\n",
    "    \n",
    "\n",
    "    data['discount_per_quantity'] = data[col1] / data[col2]  # Calculate the ratio\n",
    "    \n",
    "    return data['discount_per_quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3952efb9c9a5e72965053d005b24e6a",
     "grade": false,
     "grade_id": "cell-fdf019e6c20aa45e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['discount_per_quantity']= feature_1(data=sales,col1='discount',col2='quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eef990a45921580d13ec0179efa3491d",
     "grade": true,
     "grade_id": "cell-1d1c9c0070ebdf4e",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert round(sales['discount_per_quantity'].mean(),4)==0.0643,'Make sure that you have created feature correctly.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "51285    0.0\n",
       "51286    0.0\n",
       "51287    0.0\n",
       "51288    0.0\n",
       "51289    0.0\n",
       "Name: discount_per_quantity, Length: 51290, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['discount_per_quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06430624961106597"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['discount_per_quantity'].mean()  ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dbe4251dfc38440a7048e4ac4092e7a",
     "grade": false,
     "grade_id": "cell-04ae737147acedb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.3) Create a feature for finding cumulative sales for every customer. Return  the output series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69e435bdc1ceddfdb8f8c7fd5b067e6d",
     "grade": false,
     "grade_id": "cell-23b8a0fddaa72e30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cumulative_sales(data):\n",
    "    \n",
    "    data['cumulative_sales'] = data.groupby('customer_id')['sales'].transform(pd.Series.cumsum)  # Calculate cumulative sales\n",
    "    \n",
    "    return data['cumulative_sales']  # Return the new feature series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19dbda090f1c9bba93f2fef835d405d8",
     "grade": false,
     "grade_id": "cell-ce218cadc5b9b7b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Sorting the dataframe wrto customer_id & order_date\n",
    "sales.sort_values(['customer_id','order_date'],ascending=[1,1],inplace=True)\n",
    "### Applying cumulative_sales function\n",
    "sales['cumulative_sales']=cumulative_sales(data=sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e06c34e321f5e2e4f28e0be7918ece13",
     "grade": true,
     "grade_id": "cell-f88f29cf32252ab7",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert round(sales[sales['customer_id']=='ZC-21910']['cumulative_sales'].max(),2)==28472.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33525     673.5680\n",
       "33526     726.5480\n",
       "27383     778.2590\n",
       "27384     823.1885\n",
       "27385     852.4265\n",
       "           ...    \n",
       "39637    8100.9629\n",
       "20429    8546.2889\n",
       "15730    8762.2889\n",
       "15731    9350.3114\n",
       "15732    9479.3444\n",
       "Name: cumulative_sales, Length: 51290, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['cumulative_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28472.819260000004"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales[sales['customer_id']=='ZC-21910']['cumulative_sales'].max()    ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4128b1e3bd8a63733021c2a806f88dd0",
     "grade": false,
     "grade_id": "cell-edca82aa344fa2ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.4) Please demonstrate how to enhance a given dataset by introducing a new feature that records the frequency of same-day purchases made by each customer. The desired outcome should be a modified dataframe containing a variable named 'same_day_purchase_frequency' which accurately portrays the same-day purchase behavior of individual customers.\n",
    "\n",
    "\n",
    "Hint:\n",
    "\n",
    "1.Same_day_purchase_frequency will be the frequency of the orders made on same day. If customer 'ABC' has placed 2 orders on 2nd Jan 23 then 'same_day_purchase_frequency'for this customer for 2nd Jan 23 will be 2. This is still at Customer * Date level\n",
    "\n",
    "2.If customer  'ABC' has made say 10 such frequency transactions where frequency of same day purchase >1. Then'same_day_frequency_purchase' for customer will be 10. This is our final answer at Customer level.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdb2743d81b7f441c77e26e51ba40bac",
     "grade": false,
     "grade_id": "cell-11502c58370a30cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def same_day_purchase(data):\n",
    "    \n",
    "    # Group by 'customer_id' and date, and count the orders, store count of orders in variable named 'order_count'\n",
    "    order_counts = data.groupby(['customer_id', 'order_date'])['order_id'].count()  # Assuming 'order_id' is unique per order\n",
    "    \n",
    "    # Filter for same-day purchases (order_count > 1)\n",
    "    same_day_purchases = order_counts[order_counts > 1]\n",
    "    \n",
    "    # Group by 'customer_id' and calculate the same-day purchase frequency , name that column as 'same_day_purchase_frequency'\n",
    "    same_day_purchase_frequency = same_day_purchases.groupby('customer_id').size().rename('same_day_purchase_frequency')\n",
    "    \n",
    "    # Merge the result with the original DataFrame to add the same-day purchase frequency as a new column  \n",
    "    data = data.merge(same_day_purchase_frequency.to_frame().reset_index(), on='customer_id', how='left')\n",
    "    \n",
    "    # Fill missing values with 0 (for customers with no same-day purchases)\n",
    "    data['same_day_purchase_frequency'].fillna(0, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9485edecbbb7cf8550559814732b784",
     "grade": true,
     "grade_id": "cell-1a74a24a4da6dd2d",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales_new=same_day_purchase(data=sales.copy())\n",
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert float(sales_new[sales_new['customer_id']=='ZC-11910']['same_day_purchase_frequency'].unique())==0,'Make sure that you have created variable correctly.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_new[sales_new['customer_id']=='ZC-11910']['same_day_purchase_frequency'].unique()  ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64022a5ba581da06b8e8c96ae268fb99",
     "grade": false,
     "grade_id": "cell-7bdd8d0b6ca47c10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.5) Create a variable which will calculate weighted sales per market. Return  the output series.\n",
    "Weights for every market are :-'LATAM':1, 'EMEA':1.3, 'Africa':2.7, 'Canada':1.4, 'EU':2.8, 'APAC':3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20c298d50c1a843850662da6f77a0f4f",
     "grade": false,
     "grade_id": "cell-47084e349b64bd0d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def weighted_sales(data):\n",
    "    # Write a lambda function & apply it to dataframe.Kindly ignore raiseNotImplementError\n",
    "    weights = {'LATAM': 1, 'EMEA': 1.3, 'Africa': 2.7, 'Canada': 1.4, 'EU': 2.8, 'APAC': 3.5}\n",
    "    \n",
    "    # Define a lambda function to calculate weighted sales\n",
    "    calculate_weighted_sales = lambda row: row['sales'] * weights[row['market']]\n",
    "    \n",
    "    # Apply the lambda function to the DataFrame to create the new feature\n",
    "    data['weighted_market_sales'] = data.apply(calculate_weighted_sales, axis=1)\n",
    "    \n",
    "    return data['weighted_market_sales']  # Return the new feature series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f027b99d898df5ff494ef6222aa01040",
     "grade": false,
     "grade_id": "cell-e9fad939365ebe57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales['weighted_market_sales']=weighted_sales(data=sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82d66c7c73edac8f37f383cbfc68fafc",
     "grade": true,
     "grade_id": "cell-389d62fab17c8c2f",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert round(float(sales[(sales['market']=='Africa') & (round(sales['sales'],4)==58.83)]['weighted_market_sales'].unique()),2)==158.84, 'Make sure that ypu have created column correctly.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33525    673.5680\n",
       "33526     52.9800\n",
       "27383     51.7110\n",
       "27384     44.9295\n",
       "27385     29.2380\n",
       "           ...   \n",
       "39637     61.4400\n",
       "20429    445.3260\n",
       "15730    216.0000\n",
       "15731    588.0225\n",
       "15732    129.0330\n",
       "Name: weighted_market_sales, Length: 51290, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['weighted_market_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50986    158.841\n",
       "45637    158.841\n",
       "51154    158.841\n",
       "46996    158.841\n",
       "Name: weighted_market_sales, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sales[(sales['market']=='Africa') & (round(sales['sales'],4)==58.83)]['weighted_market_sales']) ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9afa77f2faa0eb29cbeb7b2c0dd9381d",
     "grade": false,
     "grade_id": "cell-257ca79e2212fc23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Most of the variables in our data are categorical in nature & for further anlysis purpose if we convert them by ordinal encoding or one hot encoding, we will be left with too many variables.\n",
    "If we have too many variables in the data , it might cause trouble in later stages like machine learning model building.\n",
    "1. Having too many variables can lead to overfitting and poor generalization to new data.\n",
    "2. It can make it difficult to analyze and interpret the data and identify the most important variables.\n",
    "3. It can increase computational complexity and time required to build and train a model.\n",
    "\n",
    "How to deal with this ?\n",
    "\n",
    "Wait , we have learned about **Principal component analysis** , we can leverage that method here for **dimensionality reduction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63302da6ba845b2859f2cee3e5198f4d",
     "grade": false,
     "grade_id": "cell-532602ee41242bbd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.6 ) Complete the following code for PCA implementation. Return the no of PC's required for capturing the 80% of variation, variance explained by the PC's ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73f56d08b62547c5a91e2fa94ccef16b",
     "grade": false,
     "grade_id": "cell-033f0d1768c98329",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def PCA(data,target=0.80):\n",
    "    # your code here\n",
    "    \n",
    "    # Treating ordinal variable ,\n",
    "    # order_priority : 'Medium':2, 'Low':1, 'High':3, 'Critical':4 \n",
    "    data['order_priority_encoded'] = data['order_priority'].map({'Medium': 2, 'Low': 1, 'High': 3, 'Critical': 4})\n",
    "    \n",
    "    # Treating missing values\n",
    "    # Impute the missing values in 'order_priority_encoded','ship_mode' by mode, \n",
    "    data['order_priority_encoded'].fillna(data['order_priority_encoded'].mode()[0], inplace=True)\n",
    "    data['ship_mode'].fillna(data['ship_mode'].mode()[0], inplace=True)\n",
    "    \n",
    "    # Treating Nominal variables ,'ship_mode','category','sub_category' \n",
    "    # (while encoding them make sure to select k-1 dummy variables for a variable with k categories)\n",
    "    data = pd.get_dummies(data, columns=['ship_mode', 'category', 'sub_category'], drop_first=True)\n",
    "    \n",
    "    # Final data selection\n",
    "    # Select all the variables with 'sales','quantity','discount','profit','shipping_cost',\n",
    "    # order_priority_encoded' & dummies in 'ship_mode','category','sub_category'.\n",
    "    \n",
    "    data_1 = data[['sales','quantity','discount','profit','shipping_cost','order_priority_encoded',\n",
    "                   'ship_mode_Same Day','ship_mode_Second Class','ship_mode_Standard Class',\n",
    "                   'category_Office Supplies','category_Technology','sub_category_Appliances',\n",
    "                   'sub_category_Art','sub_category_Binders','sub_category_Bookcases','sub_category_Chairs',\n",
    "                   'sub_category_Copiers','sub_category_Envelopes','sub_category_Fasteners',\n",
    "                   'sub_category_Furnishings','sub_category_Labels','sub_category_Machines',\n",
    "                   'sub_category_Paper','sub_category_Phones','sub_category_Storage',\n",
    "                   'sub_category_Supplies','sub_category_Tables']]\n",
    "    \n",
    "    # Standardize the data\n",
    "    sc = StandardScaler()\n",
    "    \n",
    "    cols = ['sales','quantity','discount','profit','shipping_cost','order_priority_encoded']\n",
    "    \n",
    "    for col in cols:\n",
    "        data_1[col] = sc.fit_transform(data_1[[col]])\n",
    "        \n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    # Create a PCA instance    \n",
    "    pca = PCA()\n",
    "    \n",
    "    # Fit PCA to the scaled data\n",
    "    pca.fit(data_1) # Write your code in place of None\n",
    "    \n",
    "    # Calculate cumulative explained variance\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "    target_variation = target\n",
    "    n_components = np.argmax(cumulative_variance >= target_variation) + 1\n",
    "    \n",
    "    # Excellent we got no of pcs which are required for capturing the target variation in the data\n",
    "    \n",
    "    ### Fitting PCA again with no of pc's we got above.\n",
    "    pca = PCA(n_components=n_components)\n",
    "    \n",
    "    # Fit PCA to the scaled data\n",
    "    pca.fit(data_1)\n",
    "    \n",
    "    #  Calculate cumulative explained variance\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "       \n",
    "    return n_components,explained_variance_ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1283ef2455ee18599ddbfc61cf61a6aa",
     "grade": true,
     "grade_id": "cell-095ce6ebc95af61e",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell.\n",
    "assert type(PCA(data=sales.copy())[0])==np.int64 , 'Number of components required for capturing target variation should be in integer format.'\n",
    "assert type(PCA(data=sales.copy())[1])==np.ndarray , 'Type of variation captured should be in an array format.'\n",
    "assert [round(x,4) for x in list(PCA(data=sales.copy())[1])][0]==0.3012, 'Make sure that you are returning correct values for output.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA(data=sales.copy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30122233, 0.14869927, 0.1394773 , 0.1093968 , 0.07239173,\n",
       "       0.04129318])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA(data=sales.copy())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3012"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[round(x,4) for x in list(PCA(data=sales.copy())[1])][0] ### PASSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6de4b32f924ec7a62617b3570a32ecfa",
     "grade": false,
     "grade_id": "cell-99f83690c838e50a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q.7) How much variation was explained by 3rd principal component ? \n",
    "**Output should be rounded upto 4 digits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b1d6d3561148f2fb0ea58db6f853f08",
     "grade": false,
     "grade_id": "cell-d668bca10bcf9149",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def var_expl(variation_explained):\n",
    "    # Kindly ignore raiseNotImplementError   \n",
    "    third_pc_variance = variation_explained[2]  # Access the 3rd PC's explained variance (index 2)\n",
    "    rounded_variance = round(third_pc_variance, 4)  # Round to 4 decimal places\n",
    "    \n",
    "    return rounded_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2b2d2a933ca3017b59536de505adc48",
     "grade": true,
     "grade_id": "cell-cf2fbc4c16e8ba3d",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder cell , please do not alter/ delete /edit this cell,Kindly ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " array([0.30122233, 0.14869927, 0.1394773 , 0.1093968 , 0.07239173,\n",
       "        0.04129316]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA(data=sales.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 93/100 points earned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
